[["index.html", "Colonial-era landscape changes are concomitant with grassland bird species declines over the last century Section 1 Introduction 1.1 Attribution 1.2 Data access 1.3 Data processing", " Colonial-era landscape changes are concomitant with grassland bird species declines over the last century Vijay Ramesh Priyanka Hari Haran Pratik Rajan Gupte Ashwini V. Mohan VA Akshay Amrutha Rajan Chandrasekar Das Ian Lockwood VV Robin Morgan W Tingley Ruth S DeFries Last compiled on 07 July, 2025 Section 1 Introduction This is the readable version that showcases how historical landscape and climatic changes have led to grassland bird species declines over the last century 1.1 Attribution Please contact the following in case of interest in the project. Vijay Ramesh (repo maintainer) Postdoctoral Research Associate, Cornell Lab of Ornithology 1.2 Data access The data used in this work will be archived on Zenodo. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],["preparing-historical-climate-data-and-geographical-covariates.html", "Section 2 Preparing historical climate data and geographical covariates 2.1 Load libraries 2.2 Reading raw historical climate data 2.3 Summarising historical climate data 2.4 Prepare study area spatial extent 2.5 Prepare spatial data for the study area 2.6 Elevation data 2.7 Distance to coast data 2.8 Latitude data 2.9 Link predictors to climate data", " Section 2 Preparing historical climate data and geographical covariates The overall aim is to prepare historical climate data associated with specific locations, and to link the data to geographical covariates. This script will prepare the data for a semi-spatial statistical model that will be used to predict historical climatic conditions across the study area. 2.1 Load libraries library(tidyverse) library(lubridate) library(terra) library(sf) 2.2 Reading raw historical climate data We first read in historical climate data from the Western Ghats, and convert them to a format suitable for further processing. This data was obtained from IIT Guwahati and the Indian Meteorological Department. Please contact the lead author for a copy of this data. We will add this to Zenodo as a release upon publication of the manuscript. The climate data are in the form of delimited text files with four columns for the daily total precipitation, minimum temperature, maximum temperature, and wind speed. Each file represents readings associated with a particular location, with coordinates indicated by the file name. We read the coordinates from the file names to assign them to each dataset. The number of rows represents the number of days of data, with a start date of 1st of January 1870, and an end date of 31st December 2018. We further classify each daily reading by the year and month, and assign each day to one of two seasons: rainy (June through November) or dry (December through May). We combine the data and filter for the southern Western Ghats as our area of interest based on the latitudinal range and write them to file. # List the climate data files and read them in, assigning column names clim_files &lt;- list.files(&quot;data/climate/historical&quot;, full.names = TRUE) data &lt;- map(clim_files, read_delim, delim = &quot; &quot;, col_names = c(&quot;ppt&quot;, &quot;tmin&quot;, &quot;tmax&quot;, &quot;wind&quot;) ) # Prepare a sequence of dates seq_date &lt;- seq( ymd(&quot;1870-01-01&quot;), ymd(&quot;2018-12-31&quot;), by = &quot;days&quot; ) # Read the coordinates from each file name # for each date, add the year and month, as well as the season data &lt;- map2( data, clim_files, function(df, clf) { # get the coordinates coords &lt;- str_extract_all(clf, &quot;\\\\d+\\\\.\\\\d+&quot;)[[1]] mutate( df, # add the date, year, and month, and season # dry season is december to may 12 - 5 date = seq_date, year = year(date), month = month(date), season = if_else(between(month, 6, 11), &quot;rainy&quot;, &quot;dry&quot;), # convert coordinates x = as.numeric(coords[2]), y = as.numeric(coords[1]) ) } ) # combine all data into a single dataframe data &lt;- bind_rows(data) # Check that the number of unique coordinates corresponds to the number of # data files (since one data file per location) assertthat::assert_that( nrow( distinct(data, x, y) ) == length(clim_files), msg = &quot;error in some weather station coordinates&quot; ) # Filter for southern western ghats # y &lt; 12 and y &gt; 9 data &lt;- filter( data, between(y, 9, 12) ) # save data write_csv( data, file = &quot;results/climate/data_clim_daily.csv&quot; ) 2.3 Summarising historical climate data We summarise the historical climate data for each location by calculating the mean daily temperature from the minimum and maximum temperature, and then calculating the monthly total precipitation, mean temperature, and the standard deviation of the mean temperature. The coordinates, year, month, and season are preserved as identifying variables. # Get daily mean temperature data &lt;- mutate( data, tmean = (tmax + tmin) / 2 ) # Group data by coordinate and select precipitation and mean daily temp. data &lt;- group_by( data, x, y, month, year, season, ) |&gt; select( ppt, tmean ) # Summarise monthly total precip. and mean and SD of temp. mean data &lt;- summarise( data, ppt = sum(ppt), t_mean = mean(tmean), t_sd = sd(tmean) ) # save summary write_csv( data, &quot;results/climate/data_monthly_climate.csv&quot; ) 2.4 Prepare study area spatial extent We prepare a spatial polygon for the extent of our area of interest. All operations are with reference to the subset of historical climate data from the southern Western Ghats. First collecting the unique locations associated with the data, we prepare a bounding box that covers all points, and then add a 25km buffer (transforming coordinates as appropriate into the UTM 43N coordinate reference system for buffer creation to ensure accurate buffer distances). # Get unique coordinates and create an `sf` points object coords &lt;- ungroup(data) |&gt; distinct(x, y) |&gt; mutate_all( as.numeric ) # Create `sf` spatial object and assign WGS 84 CRS as standard coord_sf &lt;- st_as_sf( coords, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326 ) # Create a bounding box, transform to UTM 43N CRS, and add a 25km buffer ext &lt;- st_bbox(coord_sf) |&gt; st_as_sfc() |&gt; st_transform(32643) |&gt; st_buffer(25000) |&gt; st_transform(4326) 2.5 Prepare spatial data for the study area We use the buffered spatial extent of the study area to subset (or crop) raster spatial data. We save these cropped data for further use as they are smaller and easier to work with than the full datasets. 2.6 Elevation data We read in elevation data and crop the raster to the buffered study area. # Load elevation raster and crop by buffered study area extent elevation &lt;- terra::rast(&quot;data/elevation/alt&quot;) elevation_hills &lt;- terra::crop(elevation, as(ext, &quot;Spatial&quot;)) # Save the smaller cropped elevation data in spatial TIF format terra::writeRaster( elevation_hills, &quot;results/elevation/raster_elevation.tif&quot;, overwrite = TRUE ) 2.7 Distance to coast data We prepare a synthetic raster layer for the distance of points in the study area from the coastline. Reading in vector spatial data for the boundary of India, we # Load coastline and re-load elevation coast &lt;- st_read(&quot;data/landcover/India_Boundary.shp&quot;) coast_line &lt;- st_cast(coast, &quot;MULTILINESTRING&quot;) elev &lt;- terra::rast(&quot;results/elevation/raster_elevation.tif&quot;) elev_utm &lt;- terra::project(elev, &quot;epsg:32643&quot;) We resample the elevation raster from 30m to 600m as this is the resolution of interest (converting to a UTM CRS when passing the resolution in metres). The resampled raster is also in UTM 43N projection, and we covert that WGS 84 for future use. # Resample the elevation raster to 600 m from 30m elev_utm_600 &lt;- terra::rast(ext(elev_utm), resolution = 600) elev_utm_600 &lt;- terra::resample( elev_utm, elev_utm_600 ) crs(elev_utm_600) &lt;- &quot;epsg:32643&quot; # recast to 4326 elev_600 &lt;- terra::project(elev_utm_600, &quot;epsg:4326&quot;) We prepare the distance-to-coast raster by calculating the distance between each cell in the 600m resolution elevation raster and the cost vector data; we refer to this as the coast raster on occasion. We mask (set to NA) all cells in the coast raster that are not on land. Note that this operation takes a long time to run! # Coast raster is a distance raster to the India land boundary vector # masked by the same vector; this sets all cells in the sea to zero # NOTE: this code takes a very long time to run! coast_raster &lt;- terra::distance(elev_600, terra::vect(coast_line)) coast_raster &lt;- terra::mask(coast_raster, terra::vect(coast)) 2.8 Latitude data We prepare a raster containing the latitude of each cell of the 600m resolution elevation raster in order to use this as a latitude predictor. Note: the use of terra::deepcopy() to make a copy of the elevation raster; this is to prevent the values of the elevation raster changing when the copyâ€™s values are re-assigned. See the help for terra::deepcopy() for more. # Make a deep copy of the elevation data, and assign the Y coordinate # of each cell as the latitude # NOTE: using terra::deepcopy() is a MUST to prevent reassignment of values # in elev_600 lat_raster &lt;- terra::deepcopy(elev_600) terra::values(lat_raster) &lt;- terra::yFromCell( lat_raster, cell = seq_along(values(lat_raster)) ) We combine the three data rasters into layers of a stack, and save them for later use. # Stack each data layer into a single stack stack &lt;- c(coast_raster, elev_600, lat_raster) names(stack) &lt;- c(&quot;coast&quot;, &quot;elev&quot;, &quot;lat&quot;) terra::writeRaster( stack, &quot;results/climate/raster_gam_stack.tif&quot;, overwrite = TRUE ) 2.9 Link predictors to climate data Here we link the geographical predictors â€” elevation, distance from the coast, and latitude â€” to the monthly weather data locations, in order to model the relationship between them. This is to help us get a statistical model that can be used to predict historical climate over the entire study area, in different historical periods. # Extract the elevation, distance from the coast, and latitude # at each historical climate location coords &lt;- mutate( coords, # extract elevation elev = terra::extract( elevation_hills, st_coordinates(coord_sf) )$alt, # get distance to coastline coast = as.numeric( st_distance(coord_sf, coast_line) ), # get latitude lat = y ) # Link by coordinates to the monthly climate data summary data &lt;- left_join( data, coords ) # Bin data into 10 year intervals data &lt;- mutate( data, year_bin = floor(year / 10) * 10 ) # Save data write_csv( data, &quot;results/climate/data_for_gam.csv&quot; ) "],["building-and-validating-semi-spatial-gams-for-climate.html", "Section 3 Building and validating semi-spatial GAMs for climate 3.1 Load libraries 3.2 Prepare linked climate-spatial data and spatial data for modelling 3.3 Fit candidate spatial-climate models 3.4 Model predictions for modern climate 3.5 Average predictions over 1970 to 2010 3.6 Get BIOCLIM data 3.7 Temperature data 3.8 Precipitation data 3.9 Compare spatial-climate model predictions against BIOCLIM data 3.10 Link BIOCLIM data and model predictions 3.11 Error between model prediction and CHELSA data 3.12 GAM predictions at survey sites", " Section 3 Building and validating semi-spatial GAMs for climate The overall aim here is to model historical climate variables â€” mean temperature, standard deviation in temperature, and total precipitation â€” as functions of geographical characteristics of the locations with which the data are associated. We fit three candidate models of increasing complexity. Then, the models are used to predict historical climate over the entire study area; we refer to these as semi-spatial climate models, as they include additional predictors over the coordinates of the locations alone. The climate data extend into the modern period, allowing predictions from the candidate models to be compared against data from remote sensing, in order to select the best model formulation for each climate variable in each season. 3.1 Load libraries library(tidyverse) library(sf) library(readxl) library(mgcv) # for GAMs library(terra) # for spatial rasters 3.2 Prepare linked climate-spatial data and spatial data for modelling We load the historical climate data with linked geographical covariates (hereon, climate data), and the spatial data raster stack. We prepare the covariates for modelling: distance from the coast is converted from metres to kilometres, and a small amount of random noise is added to all values. This is necessary to allow for fitting as otherwise all predictor values are identical. # read data data &lt;- read_csv(&quot;results/climate/data_for_gam.csv&quot;) # `stack` is the raster stack of geographical predictors, and not the climate # model predictions. stack &lt;- terra::rast(&quot;results/climate/raster_gam_stack.tif&quot;) # prepare data for gam fitting data &lt;- mutate( data, # divide distance by 1000 for km coast = coast / 1000, # add some error to all physical variables # hopefully prevents model issues coast = coast + rnorm(length(coast), 0.1, sd = 0.01), elev = elev + rnorm(length(coast), 1, sd = 0.01), lat = lat + rnorm(length(lat), 0, sd = 0.01) ) # set distance to coast raster in km values(stack[[&quot;coast&quot;]]) &lt;- values(stack[[&quot;coast&quot;]]) / 1000 We pivot the data to long format, and then nest the data by season and decade, gving us smaller datatsets for which models will be fit separately. While there is no specific reason to believe that the relationship between climate and geographical predictors has changed over the past 150 years, splitting the data by decade may help adjust for long-term climate system effects within certain time-periods that could be drowned out by the overall effect of geographical predictors. We subset the data for the decades between 1970 and 2010 for which reliable comparative spatial climate datasets are available from remote sensing. # Pivot to long format, remove unnecessary variables, data &lt;- pivot_longer( data, cols = c(&quot;ppt&quot;, &quot;t_mean&quot;, &quot;t_sd&quot;), names_to = &quot;climvar&quot; ) data &lt;- dplyr::select(data, !month) # Select period 1970 -- 2010 where we also have satellite data data &lt;- filter(data, between(year, 1970, 2010)) data &lt;- nest( data, data = !c(climvar, season, year_bin) ) 3.3 Fit candidate spatial-climate models We prepare three candidate spatial-climate models for each climate variable: A model where the variable is only a smooth function of elevation; A model where the variable is a smooth function of elevation, and a linear function of distance from the coast and latitude; and A model where the variable is a smooth function of elevation, and of the interaction between latitude and distance from the coast. We create combinations of each climate variable dataset (further split by decade and season) and each model formulation, and fit the variable to candidate predictors using generalised additive models (GAMs) from the mgcv package. # elevation with 3 knots form_elev_model &lt;- value ~ s(elev, k = 3) # elevation and coast form_elev_coast &lt;- value ~ s(elev, k = 3) + coast + lat # elevation and coast with lat form_elev_colat &lt;- value ~ s(elev, k = 3) + s(coast, lat, k = 5) # make combinations data &lt;- crossing( data, forms = c(form_elev_model, form_elev_coast, form_elev_colat) ) # fit models data &lt;- mutate( data, mod = map2(data, forms, function(df, form) { gam( formula = form, data = df ) }) ) # Save the fitted model data as an Rdata object save(data, file = &quot;results/climate/model_gam_climate.Rds&quot;) 3.4 Model predictions for modern climate We use the fitted models to predict climatic variables over the remainder of the study area. # ensure that NAs are removed from the stack object before running the model # projections terra::global(stack, fun = &quot;isNA&quot;) # this tells us that two raster layers within the stack object have NA values stack$coast[is.na(stack$coast)] &lt;- 0 stack$elev[stack$elev &lt; 0] &lt;- NA stack$elev[is.na(stack$elev)] &lt;- 0 stack$elev &lt;- as.numeric(stack$elev) # save model predictions model_pred &lt;- map( data$mod, function(g) { predict(stack, g, type = &quot;response&quot;) # order matters here } ) # `Reduce()` with function `c()` combines model predictions into a # single raster stack, which is then saved model_pred &lt;- Reduce(model_pred, f = c) terra::writeRaster(model_pred, &quot;results/climate/data_gam_pred.tif&quot;) # Read in the saved model predictions # this allows us to start at this stage without needing to run # previous steps model_pred &lt;- terra::rast(&quot;results/climate/data_gam_pred.tif&quot;) 3.5 Average predictions over 1970 to 2010 We combine the model predictions with the appropriate identifier variables (decade, season, climate variable, and model formulation) in the nested climate data dataframe, and get the average predicted values for each variable in each season. # assign as list column data &lt;- mutate( data, pred = as.list(model_pred) ) # Summarise rasters using a reduce over the list # basically gets the average over 1970 -- 2010 data_pred &lt;- ungroup(data) %&gt;% group_by(season, climvar, forms) %&gt;% summarise( mean_pred = list(Reduce(pred, f = mean)) ) # make raster stack gam_pred_avg &lt;- data_pred$mean_pred gam_pred_avg &lt;- Reduce(f = c, gam_pred_avg) # save averaged predictions terra::writeRaster( gam_pred_avg, filename = &quot;results/climate/gam_pred_valid_avg.tif&quot; ) We save the dataframe of season, climate variable, and model formula for future reference. # load saved pred gam_pred_avg &lt;- terra::rast(&quot;results/climate/gam_pred_valid_avg.tif&quot;) # write data for linking data_pred |&gt; # ungroup the data ungroup() |&gt; # get unique season, variable, and model formula distinct(season, climvar, forms) |&gt; # then get the model formula as a character mutate( forms = map_chr(forms, function(l) { str_flatten(as.character(l)[c(2, 1, 3)]) }) ) |&gt; # save to file write_csv( file = &quot;results/climate/gam_model_formulas.csv&quot; ) 3.6 Get BIOCLIM data In this section, we acquire remotely sensed cliamte variables for the study area, which will serve as a comparator for the values generated from fitted model predictions, and will help to pick the most appropriate model formulation to reconstruct historical climate for which remotely sensed data are not available. First, we obtained bio-climatic data from CHELSA. We do not upload the rasters to GitHub as they are very large in size and these can be downloaded from this link. 3.7 Temperature data We process monthly minimum and maximum CHELSA temperature data to get the mean monthly temperature in the dry and wet season as previously defined. # Define the patterns for data to search local data files patterns &lt;- c(&quot;tmin&quot;, &quot;tmax&quot;) # List the filepaths matching the pattern in local data (relative to the proj.) tkAvg &lt;- map(patterns, function(pattern) { # list the paths files &lt;- list.files( path = &quot;data/climate/chelsa&quot;, full.names = TRUE, recursive = TRUE, pattern = pattern ) }) # Read found rasters and crop them to the extent of other rasters representing # the study area; this is the object `stack` tkAvg &lt;- map(tkAvg, function(paths) { # going over the file paths, read them in as rasters, convert CRS and crop tempData &lt;- map(paths, function(path) { a &lt;- terra::rast(path) a &lt;- terra::crop(a, terra::ext(stack)) a }) # The data are in a native format that needs to be converted before # processing. # Convert each to Kelvin, first dividing by 10 to get celsius tempData &lt;- map(tempData, function(tmpRaster) { tmpRaster &lt;- (tmpRaster / 10) + 273.15 tmpRaster }) }) # Iteratively get the mean temperature for each month, and assign # names to the resulting raster stacks names(tkAvg) &lt;- patterns # go over the tmin and tmax and get the average monthly temp tkAvg &lt;- map2(tkAvg[[&quot;tmin&quot;]], tkAvg[[&quot;tmax&quot;]], function(tmin, tmax) { # return the mean of the corresponding tmin and tmax # still in Kelvin terra::mean(c(tmin, tmax)) }) # Error if the there are fewer than 12 output layers assertthat::assert_that( length(tkAvg) == 12, msg = &quot;temp raster list has fewer than 12 months&quot; ) # Assign names to identify months names(tkAvg) &lt;- sprintf(&quot;month_%i&quot;, seq(12)) # Separate data for the rainy and dry seasons to get the # rainy and dry season mean monthyl temperature temp_rainy &lt;- Reduce(tkAvg[seq(6, 11)], f = `c`) |&gt; terra::mean() temp_dry &lt;- Reduce(tkAvg[c(12, seq(5))], f = `c`) |&gt; terra::mean() # Convert values back to celsius chelsa_t_mean &lt;- c(temp_rainy, temp_dry) - 273.15 names(chelsa_t_mean) &lt;- c(&quot;chelsa_temp_rainy_6_11&quot;, &quot;chelsa_temp_dry_12_5&quot;) # Save stack terra::writeRaster( chelsa_t_mean, filename = &quot;results/climate/chelsa_temp_stack.tif&quot;, overwrite = TRUE ) 3.8 Precipitation data We process total monthly precipitation data from CHELSA to get the mean monthly temperature in the dry and wet seasons in millimetres. # List precipitation rasters stored locally (relative to this project) ppt &lt;- list.files( path = &quot;data/climate/chelsa&quot;, full.names = TRUE, recursive = TRUE, pattern = &quot;prec&quot; ) # Read each as rasters and crop by extent of study area ppt &lt;- map(ppt, function(path) { a &lt;- terra::rast(path) terra::crop(a, terra::ext(stack)) }) # Separate rainy and dry season and get the mean total monthly precipitation ppt_rainy &lt;- Reduce(ppt[seq(6, 11)], f = `c`) |&gt; terra::mean() ppt_dry &lt;- Reduce(ppt[c(12, seq(5))], f = `c`) |&gt; terra::mean() # Make and save stack chelsa_ppt_sum &lt;- c(ppt_rainy, ppt_dry) names(chelsa_ppt_sum) &lt;- c(&quot;chelsa_ppt_rainy_6_11&quot;, &quot;chelsa_ppt_dry_12_5&quot;) terra::writeRaster( chelsa_ppt_sum, filename = &quot;results/climate/chelsa_ppt_stack.tif&quot;, overwrite = TRUE ) 3.9 Compare spatial-climate model predictions against BIOCLIM data First we draw 10,000 randomly selected coordinates from the extent of the study area, and use these to compare the model predictions against CHELSA-derived data. We will further stratify these into 10 arbitrary groups at a later stage. # get coordinates from terra coords &lt;- terra::xyFromCell( stack, cell = seq(length(values(stack[[1]]))) ) # Sample 1000 locations from the raster data coordinates # Use `withr::with_local_seed()` to preserve which coordinates are selected # in each analysis run coords &lt;- withr::with_seed( 1, coords[sample(1e4, replace = FALSE), ] ) |&gt; as_tibble() # Extract geographical predictors and CHELSA data at locations # NOTE: recall that `stack` is the raster stack of geographical predictors sample_locations &lt;- mutate( coords, terra::extract(stack, coords) ) |&gt; mutate( terra::extract(chelsa_ppt_sum, coords) ) |&gt; mutate( terra::extract(chelsa_t_mean, coords) ) # save data write_csv( sample_locations, file = &quot;results/climate/data_sample_coords_gam_validation.csv&quot; ) 3.10 Link BIOCLIM data and model predictions Next we link the remote-sensing-derived BIOCLIM data at the sampled locations with the predicted values from our spatial-climate GAMs. # Read in the saved data; this allows continuing from this point without # re-running the previous code sample_locations &lt;- read_csv( &quot;results/climate/data_sample_coords_gam_validation.csv&quot; ) # Pivot the data to long format, retaining coordinates, ID, and geographical # predictors as identifying variables sample_locations &lt;- sample_locations |&gt; pivot_longer( cols = !c(&quot;x&quot;, &quot;y&quot;, &quot;ID&quot;, &quot;coast&quot;, &quot;elev&quot;, &quot;lat&quot;) ) # Assign the season and identify the variable from the variable name sample_locations &lt;- mutate( sample_locations, season = str_extract( name, pattern = &quot;dry|rainy&quot; ), climvar = str_extract( name, pattern = &quot;temp|ppt&quot; ), climvar = if_else( climvar == &quot;temp&quot;, &quot;t_mean&quot;, &quot;ppt&quot; ) ) We link the spatial-climate modelsâ€™ predictions. Recall that there are three candidate models for each variable, in each season, and the aim is to select a model formulation for the remaining historical data based on minimising deviation from the BIOCLIM data. # Filter the climate-model predictions to remove the SD of temperature data_pred &lt;- filter( data_pred, climvar != &quot;t_sd&quot; ) # Nest model predictions by season and variable sample_locations &lt;- nest( sample_locations, chelsa = !c(&quot;season&quot;, &quot;climvar&quot;) ) # Link predictions for sampled locations with CHELSA data rasters and # geographical predictors data_pred &lt;- left_join( data_pred, sample_locations ) Since the model prediction rasters are stored as-is, we need to extract the values at the coordinates from those rasters. # For each climate variable, extract the predicted values at the sampled # locations data_pred &lt;- mutate( data_pred, chelsa = map2(chelsa, mean_pred, function(ch, pr) { ch |&gt; rename( bioclim_val = &quot;value&quot; ) |&gt; mutate( pred_val = terra::extract(pr, ch[, c(&quot;x&quot;, &quot;y&quot;)]) # the naming doesn&#39;t quite work ) }) ) # Make a copy for further operations data_gam_validate &lt;- data_pred |&gt; select(season, climvar, forms, chelsa) # Unnest data data_gam_validate &lt;- unnest( data_gam_validate, cols = chelsa ) # Convert model formula from formula to characters data_gam_validate &lt;- mutate( data_gam_validate, forms = as.character(forms) ) # Extract the predicted values data_gam_validate &lt;- data_gam_validate |&gt; mutate( pred_val = pred_val$lyr1 ) # Drop some variables and save data write_csv( data_gam_validate, file = &quot;results/climate/data_gam_validate_compare.csv&quot; ) 3.11 Error between model prediction and CHELSA data We use mean absolute error (MAE) as a measure of how much the model predictions deviate from the CHELSA data. In order to calculate the mean, we group the data into ten arbitrary groups of 1,000 samples each. We calculate MAE as the mean of the absolute differences between the CHELSA data and the model predicted data, and save the data to a local file. MAE is calculated for each climate variable, model formulation, and season separately (in addition to the sample group, which is arbitrary). # Group samples into 10 chunks of 1000 coordinates each data_gam_validate &lt;- group_by( data_gam_validate, season, climvar, forms ) |&gt; mutate( group = rep(seq(10), each = 1e3L) ) # Grouping by season, climate variable, and model formula, calculate MAE data_mae &lt;- group_by( data_gam_validate, season, climvar, forms, group ) |&gt; summarise( mae = mean( abs( bioclim_val - pred_val ), na.rm = TRUE ) ) # Save data write_csv( data_mae, file = &quot;results/climate/data_gam_comparison_mae.csv&quot; ) 3.12 GAM predictions at survey sites In this section, we get the spatial-climate model predictions at the modern survey site locations (called â€˜survey sitesâ€™). This is a repitition of the steps above for the much smaller subset of survery sites. Recall that for each survey site, there will be three candidate model predictions for each climate variable in each season. # Read survey sites from a local file survey_sites &lt;- read.csv(&quot;data/list-of-resurvey-locations.csv&quot;) names(survey_sites)[4] &lt;- &quot;x&quot; names(survey_sites)[5] &lt;- &quot;y&quot; # Sample BIOCLIM rasters at survey sites survey_sites &lt;- mutate( survey_sites, terra::extract( c(chelsa_t_mean, chelsa_ppt_sum), survey_sites[, c(&quot;x&quot;, &quot;y&quot;)] ) ) # Remove survery site id, keeping only the &#39;modern_site_code&#39; survey_sites &lt;- select( survey_sites, -c(site_name, historical_site_code, modern_landCover_type, ID) ) # Pivot the data to long format and identify the season and climate # variable from the variable name (this is autogenerated by `terra::extract()`) survey_sites &lt;- pivot_longer( survey_sites, cols = !c(&quot;modern_site_code&quot;, &quot;x&quot;, &quot;y&quot;) ) |&gt; mutate( season = str_extract( name, pattern = &quot;dry|rainy&quot; ), climvar = str_extract( name, pattern = &quot;temp|ppt&quot; ), climvar = if_else( climvar == &quot;temp&quot;, &quot;t_mean&quot;, &quot;ppt&quot; ) ) # Nest data, and remove the linked rasters survey_sites &lt;- nest( survey_sites, chelsa = !c(&quot;season&quot;, &quot;climvar&quot;) ) data_pred &lt;- select(data_pred, -chelsa) # remove rasters as data extracted # Link survey data coordinates with model prediction data survey_sites &lt;- left_join( survey_sites, data_pred ) # For each survey site location, extract model-predicted values from # the model-prediction rasters survey_sites &lt;- mutate( survey_sites, chelsa = map2(chelsa, mean_pred, function(ch, pr) { ch |&gt; rename( bioclim_val = &quot;value&quot; ) |&gt; mutate( pred_val = terra::extract(pr, ch[, c(&quot;x&quot;, &quot;y&quot;)])$lyr1 # the naming doesn&#39;t quite work ) }) ) # Convert the model forumlae in the data to characters and unnest the # CHELSA data survey_sites &lt;- survey_sites |&gt; select(season, climvar, chelsa, forms) |&gt; mutate( forms = as.character(forms) ) |&gt; unnest( cols = chelsa ) # Save the CHELSA and predicted measures at survey sites write_csv( survey_sites, file = &quot;results/climate/data_gam_compare_survey_sites.csv&quot; ) "],["building-a-correction-layer-for-climate-predictions.html", "Section 4 Building a correction layer for climate predictions 4.1 Load libraries 4.2 Plot model error 4.3 Compare climate predictions at survey sites 4.4 Visualise model predictions as proportion of remote sensing data 4.5 Temperature scaling layer 4.6 Precipitation scaling layer 4.7 Save climate scaling layers 4.8 Seasonal mean temperature correction layer 4.9 Seasonal total rainfall correction layer", " Section 4 Building a correction layer for climate predictions In this script, we focus on quantifying the error over the entire study site between model-predicted climate and climate measures derived from remote sensing data (from BIOCLIM, and referred to as CHELSA data). We then use these differences to create a â€˜correction layerâ€™, that allows us to scale the model predictions for historical data. The assumption is that the correction layer is applicable to historical climate model predictions. 4.1 Load libraries library(tidyverse) library(ggplot2) library(colorspace) library(patchwork) library(terra) library(stars) error_data &lt;- read_csv(&quot;results/climate/data_gam_comparison_mae.csv&quot;) survey_clim &lt;- read_csv(&quot;results/climate/data_gam_compare_survey_sites.csv&quot;) # load saved object from previous script load(&quot;results/climate/model_pred_climate.Rds&quot;) 4.2 Plot model error Here we plot the mean absolute error (MAE) between CHELSA data and model predicted data in each season (dry or rainy) using boxplots. Recall that this is for the 10,000 sampled locations split into 10 groups of 1,000 locations to calculate MAE. # Nest data by climate variable error_data &lt;- nest( error_data, data = !c(&quot;climvar&quot;) ) # Get the distinct values of the model formulae forms &lt;- distinct(survey_clim, form = forms) # Map over each climate variable, producing a list of ggplots plots &lt;- map2( error_data$data, error_data$climvar, function(df, cl) { ggplot(df) + geom_boxplot( aes( forms, mae ), width = 0.5 ) + geom_text( data = forms, aes( form, 1, label = form ), angle = 90, hjust = &quot;inward&quot;, nudge_x = -0.5, col = &quot;steelblue&quot;, alpha = 0.6, fontface = &quot;italic&quot; ) + scale_y_log10() + facet_wrap( ~season, labeller = label_both ) + theme_grey(base_size = 10) + theme( strip.background = element_blank(), axis.text.y = element_text( angle = 90, hjust = 0.5 ), axis.text.x = element_blank(), panel.border = element_rect( fill = NA, colour = &quot;black&quot; ) ) + labs( x = &quot;GAM formula&quot;, y = &quot;Mean absolute error&quot;, title = ifelse( cl == &quot;ppt&quot;, &quot;Precipitation&quot;, &quot;Mean temperature&quot; ) ) } ) # Combine into a single plot to save plots &lt;- wrap_plots( plots, ncol = 1 ) + plot_annotation( tag_levels = &quot;A&quot; ) &amp; theme( plot.tag = element_text( face = &quot;bold&quot; ) ) # Save the plot for future reference ggsave( plots, filename = &quot;figs/fig_compare_models_general.png&quot;, width = 6, height = 8 ) dev.off() Comparing the mean absolute errors for the precipitation and temperature models 4.3 Compare climate predictions at survey sites Next we plot the model-predicted climate variable values against the equivalent remote-sensing derived climate values at each of the modern resurvey locations, separating by model formulation and season. # Nest the data by climate variable and season survey_clim &lt;- group_by(survey_clim, climvar, season) |&gt; nest() # For each climate variable and season, produce a separate plot # Plots form a list of ggplot objects plots_survey_pts &lt;- Map( survey_clim$climvar, survey_clim$data, survey_clim$season, f = function(cvar, df, season) { ggplot( df ) + geom_abline( slope = 1 ) + geom_point( aes(bioclim_val, pred_val), shape = 1, alpha = 0.8 ) + scale_y_continuous() + facet_grid( ~forms, scales = &quot;free&quot;, labeller = labeller( .multi_line = F, season = label_both ) ) + theme_grey( base_size = 8 ) + theme( legend.position = &quot;top&quot;, panel.border = element_rect( fill = NA, colour = &quot;black&quot; ) ) + labs( colur = &quot;Model&quot;, title = ifelse( cvar == &quot;ppt&quot;, glue::glue(&quot;Precipation; season: {season}&quot;), glue::glue(&quot;Mean temperature; season: {season}&quot;) ) ) } ) # Combine plots into a single plot plots_survey_pts &lt;- wrap_plots( plots_survey_pts, ncol = 1 ) + plot_annotation( tag_levels = &quot;A&quot; ) # Save the plot for future reference ggsave( plots_survey_pts, filename = &quot;figs/fig_survey_site_model_comparison.png&quot;, height = 10, width = 6 ) Comparing predicted values vs.Â data from Bioclim for rainy and dry seasons for both temperature and precipitation data 4.4 Visualise model predictions as proportion of remote sensing data Here, we obtain the model-predicted climate data (for each variable in each season) and express it as a proportion of the CHELSA value for the same variable, which we take as the canonical value. # Read in the raster data of model predictions gam_validation_pred &lt;- terra::rast(&quot;results/climate/gam_pred_valid_avg.tif&quot;) |&gt; as.list() # Read in the data for season, climate variable, and model formulation gam_validation_id &lt;- read_csv(&quot;results/climate/gam_model_formulas.csv&quot;) # Select only data for climate variables precip. and temp. mean # and assign raster data as a list column gam_validation_pred &lt;- gam_validation_pred[gam_validation_id$climvar %in% c(&quot;ppt&quot;, &quot;t_mean&quot;)] gam_validation_id &lt;- filter(gam_validation_id, climvar %in% c(&quot;ppt&quot;, &quot;t_mean&quot;)) gam_validation_data &lt;- mutate( gam_validation_id, prediction = gam_validation_pred ) Next we load the BIOCLIM data and prepare variables that allow it to be merged with the model-predictions dataframe. # Read in BIOCLIM/CHELSA rasters chelsa_temp &lt;- terra::rast(&quot;results/climate/chelsa_temp_stack.tif&quot;) |&gt; as.list() chelsa_ppt &lt;- terra::rast(&quot;results/climate/chelsa_ppt_stack.tif&quot;) |&gt; as.list() # Make a dataframe with combinations of season and climate variable # and assing the raster data as a list column chelsa_data &lt;- crossing( season = c(&quot;rainy&quot;, &quot;dry&quot;), climvar = c(&quot;t_mean&quot;, &quot;ppt&quot;) ) |&gt; arrange(desc(climvar), desc(season)) |&gt; mutate( chelsa_rast = append(chelsa_temp, chelsa_ppt) ) We merge the CHELSA data with the model-prediction and get the scaling layer (called â€˜residualâ€™), which is the prediction as a proportion of the canonical CHELSA data. # link prediction and residual gam_validation_data &lt;- gam_validation_data |&gt; left_join(chelsa_data) gam_validation_data &lt;- mutate( gam_validation_data, residual = map2(chelsa_rast, prediction, function(ch, pr) { pr &lt;- terra::resample(pr, ch) # resampling required pr / ch }) ) 4.5 Temperature scaling layer We plot the scaling layer for temperature. The general pattern is that all models overestimate temperature in hilly regions of the study area; higher elevations have a higher ratio of prediction to CHELSA in all models. In contrast, lower elevations have a prediction to CHELSA ratio close to 1.0 in all models, i.e., the model prediction is relatively good in the non-hilly areas. plots_temp_resid &lt;- filter(gam_validation_data, climvar == &quot;t_mean&quot;) |&gt; select(-prediction, -chelsa_rast) plots_temp_resid &lt;- pmap( plots_temp_resid, .f = function(season, climvar, forms, residual) { residual &lt;- st_as_stars(residual) ggplot() + geom_stars( data = residual ) + scale_fill_continuous_diverging( palette = &quot;Blue-Red 3&quot;, mid = 1, na.value = &quot;transparent&quot;, name = glue::glue(&quot;Prediction / BIOCLIM {climvar}&quot;), limits = c(0.5, 2), labels = scales::percent, trans = ggallin::ssqrt_trans ) + theme_test(base_size = 6) + theme( legend.position = &quot;right&quot;, legend.key.height = unit(10, &quot;mm&quot;), legend.key.width = unit(2, &quot;mm&quot;), axis.title = element_blank() ) + coord_sf( expand = F ) + labs( title = glue::glue(&quot;variable: {climvar} season: {season} model: {forms}&quot;) ) } ) |&gt; wrap_plots( guides = &quot;collect&quot; ) &amp; theme( legend.position = &quot;right&quot; ) plots_temp_resid[[1]] 4.6 Precipitation scaling layer We plot the scaling layer for precipitation. The general pattern is that all models overestimate precipitation on the leeward side of the study area, i.e., in the rain shadow of the Western Ghats, while underestimating precipitation on the windward side. This makes sense as the driver of canonical variation is largely the blocking of monsoon winds and associated rainfall by the Ghats; while this could be expected to be captured by the distance-to-coast variable, it does not appear to do so well. The underestimation of precipitation on the windward side is more pronounced in the rainy season, which is expected. Higher elevations also have a lower prediction to CHELSA ratio than lower elevations on the windward side. plots_ppt_resid &lt;- filter(gam_validation_data, climvar == &quot;ppt&quot;) |&gt; select(-prediction, -chelsa_rast) plots_ppt_resid &lt;- pmap( plots_ppt_resid, .f = function(season, climvar, forms, residual) { residual &lt;- st_as_stars(residual) ggplot() + geom_stars( data = residual ) + scale_fill_continuous_diverging( palette = &quot;Vik&quot;, rev = TRUE, mid = 1, na.value = &quot;transparent&quot;, name = glue::glue(&quot;Prediction / BIOCLIM {climvar}&quot;), limits = c(0.1, 5.5), labels = scales::percent, breaks = c(0.01, 0.5, seq(0.0, 5.5, 1)) ) + theme_test(base_size = 6) + theme( legend.position = &quot;right&quot;, legend.key.height = unit(10, &quot;mm&quot;), legend.key.width = unit(2, &quot;mm&quot;), axis.title = element_blank() ) + coord_sf( expand = F ) + labs( title = glue::glue(&quot;variable: {climvar} season: {season} model: {forms}&quot;) ) } ) |&gt; wrap_plots( guides = &quot;collect&quot; ) &amp; theme( legend.position = &quot;right&quot; ) plots_ppt_resid[[1]] # Save the scaling layer plots for future reference ggsave( plots_temp_resid, filename = &quot;figs/fig_temp_resid.png&quot;, width = 9, height = 7 ) ggsave( plots_ppt_resid, filename = &quot;figs/fig_ppt_resid.png&quot;, width = 9, height = 7 ) Bioclimatic prediction across GAM models for temperature Bioclimatic predictions for precipitation 4.7 Save climate scaling layers Looking at the GAM predictions as proportions of the BIOCLIM layers, we can choose model formulas for each season and each variable that lead to predictions that are closest to the real BIOCLIM values. We choose formulas on the basis of observed deviation from the true value, as well as spatial contiguity of deviations, basically, are nearby areas similarly different from true values. For example, there is an odd north east regional deviation for rainfall in the wet season for the forumla \\(\\text{ppt} ~ s(\\text{elevation}, k = 3) + s(\\text{distance to coast, latitude}, k = 5)\\), so we prefer to chose another formula. This means we pick the simple \\(\\text{temp} ~ s(\\text{elevation}, k = 3)\\) formula for mean monthly temperature, in both dry and wet seasons, and the \\(\\text{ppt} ~ s(\\text{elevation}, k = 3) + \\text{distance to coast} + \\text{latitude}\\) formula for total monthly rainfall in both dry and wet seasons. We then save the inverse proportion, BIOCLIM / prediction, as a correction layer â€” one layer per season and variable. This allows us to fit GAMs to chunks of historical climate data, using physical predictors as covariates, and to then correct the resulting spatial prediction using the correction layer. Hence the â€˜trueâ€™ historical value of a climate variable is \\(\\text{GAM prediction} \\times \\text{correction factor}\\), where the correction factor is the cell-specific value from the correction layers. 4.8 Seasonal mean temperature correction layer We prepare the season-specific mean temperature correction layer. # Subset validation dataset temp_correction_layer &lt;- gam_validation_data %&gt;% filter( climvar == &quot;t_mean&quot;, forms == &quot;value~s(elev, k = 3)&quot; ) # Get the correction layer as CHELSA / prediction temp_correction_layer &lt;- mutate( temp_correction_layer, correction_layer = map2( chelsa_rast, prediction, function(ch, pr) { pr &lt;- terra::resample(pr, ch) # resampling required ch / pr } ) ) # Make the correction layer a single raster stack object and name correctly temp_correction_layer &lt;- Reduce( temp_correction_layer$correction_layer, f = c ) # Set names for layers names(temp_correction_layer) &lt;- c( &quot;correction_layer_temp_dry&quot;, &quot;correction_layer_temp_wet&quot; ) # Save the correction layer terra::writeRaster( temp_correction_layer, filename = &quot;results/climate/raster_correction_layers_temp.tif&quot; ) 4.9 Seasonal total rainfall correction layer We prepare the season-specific total precipitation correction layer. # Subset validation dataset ppt_correction_layer &lt;- gam_validation_data %&gt;% filter( climvar == &quot;ppt&quot;, forms == &quot;value~s(elev, k = 3) + coast + lat&quot; ) # Now get the correction layer as CHELSA / prediction ppt_correction_layer &lt;- mutate( ppt_correction_layer, correction_layer = map2( chelsa_rast, prediction, function(ch, pr) { pr &lt;- terra::resample(pr, ch) # resampling required ch / pr } ) ) # Make the correction layer a single raster stack object and name correctly ppt_correction_layer &lt;- Reduce( ppt_correction_layer$correction_layer, f = c ) # Set names for layers names(ppt_correction_layer) &lt;- c( &quot;correction_layer_ppt_dry&quot;, &quot;correction_layer_ppt_wet&quot; ) # Save the layer terra::writeRaster( ppt_correction_layer, filename = &quot;results/climate/raster_correction_layers_ppt.tif&quot; ) "],["modelling-historical-climate-over-the-study-area.html", "Section 5 Modelling historical climate over the study area 5.1 Load libraries 5.2 Read in data 5.3 Model climate as a function of geographic variables 5.4 Obtaining model predictions over the study area 5.5 Scaling predicted historical climate", " Section 5 Modelling historical climate over the study area Here we use the model formulation chosen in the previous section to model climate variables as a function of geographical predictors over the study area. We use one model formula (henceforth, model) for each climate variable in each season. We model historical climate for 30 year periods, as this is about the temporal resolution of interest. 5.1 Load libraries # for data library(tidyverse) library(glue) # for gam library(mgcv) # for rasters library(terra) 5.2 Read in data # Read in geographical covariates of weather data locations # and rasters of spatial data data &lt;- read_csv(&quot;results/climate/data_for_gam.csv&quot;) stack &lt;- terra::rast(&quot;results/climate/raster_gam_stack.tif&quot;) 5.3 Model climate as a function of geographic variables Here we prepare the data and model climate variables as a function of geographic variables. As in the section on modelling the contemporary climate, we add some small error to each geographic variable to facilitate model fitting. # Prepare geographic variables data &lt;- mutate( data, # divide distance by 1000 for km coast = coast / 1000, # add some error to all physical variables # hopefully prevents model issues coast = coast + rnorm(length(coast), 0.1, sd = 0.01), elev = elev + rnorm(length(coast), 1, sd = 0.01), lat = lat + rnorm(length(lat), 0, sd = 0.01) ) # set distance to coast raster in km values(stack[[&quot;coast&quot;]]) &lt;- values(stack[[&quot;coast&quot;]]) / 1000 # Pivot the data to long format and remove the SD of temperature data &lt;- pivot_longer( data, cols = c(&quot;ppt&quot;, &quot;t_mean&quot;, &quot;t_sd&quot;), names_to = &quot;climvar&quot; ) data &lt;- dplyr::select(data, !month) # remove t_sd data &lt;- filter( data, climvar != &quot;t_sd&quot; ) # Nest the data by climate variable, season, and 30-year bin data &lt;- nest( data, data = !c(climvar, season, year_bin) ) We specify the GAM formulas for temperature and precipitation, chosen in the previous section after examining the mean absolute error (MAE) of predictions for contemporary data (i.e., compared against remotely sensed data). Temperature is modelled as a smooth function of elevation with three knots. Precipitation is modelled as a smooth function of elevation with three knots, with linear terms for distance from the coast and latitude. # model formula for temp form_temp &lt;- &quot;value ~ s(elev, k = 3)&quot; # model formula for ppt form_ppt &lt;- &quot;value ~ s(elev, k = 3) + coast + lat&quot; # Assign formula as a character column in the nested data.frame data &lt;- mutate( data, form = if_else( climvar == &quot;t_mean&quot;, form_temp, form_ppt ) ) # Fit models for each climate variable, season, and year bin # Note that the formulae are converted to the `&lt;formula&gt;` class # using `as.formula()` data &lt;- mutate( data, mod = map2(data, form, function(df, form) { gam( formula = as.formula(form), data = df ) }) ) # NOTE: if mgcv::gam() is excessively slow, consider mgcv::bam() which is # said to be more suitable for large datasets We save the model as an R data object. save(data, file = &quot;results/climate/model_reconstruction_climate.Rds&quot;) 5.4 Obtaining model predictions over the study area We use the predict() method to get climate predictions over the study area, using the spatial raster data as inputs. # ensure that NAs are removed from the stack object before running the model # projections # this tells us that two raster layers within the stack object have NA values terra::global(stack, fun = &quot;isNA&quot;) # Replace NAs with 0s for distance to coast stack$coast[is.na(stack$coast)] &lt;- 0 # Replace elevations &lt; 0 with NA and then 0 stack$elev[stack$elev &lt; 0] &lt;- NA stack$elev[is.na(stack$elev)] &lt;- 0 stack$elev &lt;- as.numeric(stack$elev) # Get model predictions model_pred &lt;- map( data$mod, function(g) { predict(stack, g, type = &quot;response&quot;) # order matters here } ) # Assign predicted climate rasters as list column object data &lt;- mutate( data, pred = model_pred ) # Ungroup the data and select relevant columns data_pred &lt;- ungroup(data) %&gt;% select(season, year_bin, climvar, pred) 5.5 Scaling predicted historical climate Here we aim to scale the predicted historical climate using the scaling layers developed in the previous section. The idea is that the predicted historical climate differs from the true historical climate over the study area in the same way (i.e., with the same ratio) that the contemporary climate prediction differs from the canonical (remotely sensed) climate variables. We read in the scaling layers and apply them to the data (taking the cell-wise product of the two). # Read in scaling layers temp_correction &lt;- terra::rast( &quot;results/climate/raster_correction_layers_temp.tif&quot; ) ppt_correction &lt;- terra::rast( &quot;results/climate/raster_correction_layers_ppt.tif&quot; ) # Match scaling layers to the appropriate prediction layer data_pred &lt;- mutate( data_pred, correction = map2( season, climvar, function(season, climvar) { if (season == &quot;dry&quot; &amp; climvar == &quot;ppt&quot;) { ppt_correction[[&quot;correction_layer_ppt_dry&quot;]] } else if (season == &quot;dry&quot; &amp; climvar == &quot;temp&quot;) { temp_correction[[&quot;correction_layer_temp_dry&quot;]] } else if (season == &quot;wet&quot; &amp; climvar == &quot;ppt&quot;) { ppt_correction[[&quot;correction_layer_ppt_wet&quot;]] } else { temp_correction[[&quot;correction_layer_temp_wet&quot;]] } } ) ) # Scale predicted historical climate by cell-wise product of # prediction and scaling layer data_pred &lt;- mutate( data_pred, corrected = map2( correction, pred, function(ch, pr) { pr &lt;- terra::resample(pr, ch) # resampling required ch * pr } ) ) # Assign names to corrected rasters data_pred &lt;- mutate( data_pred, names = glue(&quot;{climvar}_{year_bin}_{season}&quot;) ) names(data_pred$corrected) &lt;- data_pred$names # Collect the predictions for each season and climate variable # into one raster stack each # Each stack has multiple layers, each representing one 30-year bin data_reconstructed &lt;- data_pred %&gt;% group_by( season, climvar ) %&gt;% summarise( corrected = list(Reduce(corrected, f = c)) ) # Save each raster stack as a TIF file pwalk( data_reconstructed, function(season, climvar, corrected) { names(corrected) &lt;- glue(&quot;{climvar}_{season}_{seq(1870, 2018, 10)}&quot;) terra::writeRaster( corrected, glue(&quot;results/climate/raster_reconstructed_{climvar}_{season}.tif&quot;) ) } ) "],["analyzing-temperature-and-precipitation-change-over-time.html", "Section 6 Analyzing temperature and precipitation change over time 6.1 Load necessary libraries 6.2 Plot change in climate as percentages. 6.3 Load list of resurvey locations/historical sites of occurrence 6.4 Load the climate rasters 6.5 Combine site climate and terrain data 6.6 Plot all reconstructed climate over time colouring by elevation and grouping by site. Each line represents one modern site code. 6.7 Alternative figure for temperature change over time 6.8 Test for climate change over time", " Section 6 Analyzing temperature and precipitation change over time In this script, we will process the reconstructed climate data and analyze trends in climate over time 6.1 Load necessary libraries library(terra) library(sf) library(stringi) library(glue) library(purrr) library(dplyr) library(tidyr) library(tibble) # for plotting library(viridis) library(colorspace) library(tmap) library(scales) library(ggplot2) library(patchwork) # for GLMMS library(mgcv) # load nilgiris hills &lt;- st_read(&quot;data/landcover/Nil_Ana_Pal.shp&quot;) # get reconstructions climate_reconstructed &lt;- list.files( &quot;results/climate&quot;, pattern = &quot;raster_reconstructed&quot;, full.names = T ) |&gt; lapply(rast) # get differences with respect to first reconstruction climate_change &lt;- lapply(climate_reconstructed, function(le) { le &lt;- le / le[[1]] le &lt;- le[[-1]] le &lt;- le - 1 terra::crop( le, vect(hills) ) }) 6.2 Plot change in climate as percentages. ppt_dry_change &lt;- tm_shape(climate_change[[1]]) + tm_raster( palette = colorspace::diverging_hcl( 31, palette = &quot;Blue-Yellow&quot;, rev = T ), style = &quot;cont&quot;, midpoint = 0, title = &quot;% difference, dry season ppt.&quot;, legend.is.portrait = F ) + tm_shape(hills) + tm_borders() + tm_legend( legend.outside = T, legend.outside.position = &quot;bottom&quot;, legend.outside.size = .1 ) tmap_save( ppt_dry_change, filename = &quot;figs/fig_ppt_dry_change.png&quot; ) Decadal changes in dry season precipitation over the last century ppt_wet_change &lt;- tm_shape(climate_change[[2]]) + tm_raster( palette = colorspace::diverging_hcl( 31, palette = &quot;Blue-Yellow&quot;, rev = T ), style = &quot;cont&quot;, midpoint = 0, title = &quot;% difference, wet season ppt.&quot;, legend.is.portrait = F ) + tm_shape(hills) + tm_borders() + tm_legend( legend.outside = T, legend.outside.position = &quot;bottom&quot;, legend.outside.size = .1 ) tmap_save( ppt_wet_change, filename = &quot;figs/fig_ppt_wet_change.png&quot; ) Decadal changes in rainy season precipitation over the last century temp_dry_change &lt;- tm_shape(climate_change[[3]]) + tm_raster( palette = colorspace::diverging_hcl( 31, rev = F ), style = &quot;cont&quot;, midpoint = 0, title = &quot;% difference, dry season temp.&quot;, legend.is.portrait = F ) + tm_shape(hills) + tm_borders() + tm_legend( legend.outside = T, legend.outside.position = &quot;bottom&quot;, legend.outside.size = .1 ) tmap_save( temp_dry_change, filename = &quot;figs/fig_temp_dry_change.png&quot; ) Decadal change in dry season temperatures over the last century temp_wet_change &lt;- tm_shape(climate_change[[4]]) + tm_raster( palette = colorspace::diverging_hcl( 31, rev = F ), style = &quot;cont&quot;, midpoint = 0, title = &quot;% difference, wet season temp.&quot;, legend.is.portrait = F ) + tm_shape(hills) + tm_borders() + tm_legend( legend.outside = T, legend.outside.position = &quot;bottom&quot;, legend.outside.size = .1 ) tmap_save( temp_wet_change, filename = &quot;figs/fig_temp_wet_change.png&quot; ) Decadal change in wet season temperatures over the last century 6.3 Load list of resurvey locations/historical sites of occurrence # load list of resurvey locations and add elevation as a variable # remove the modern resurvey locations only (ie. ASFQ) sites &lt;- read.csv(&quot;data/list-of-resurvey-locations.csv&quot;) # set missing historical site code to NA sites &lt;- mutate(sites, historical_site_code = if_else( historical_site_code == &quot;&quot;, NA_character_, historical_site_code ), site_name = if_else( site_name == &quot;&quot;, NA_character_, site_name ) ) # remove sites with historical site code missing sites &lt;- filter(sites, !is.na(historical_site_code)) # convert to sf object and transform sites &lt;- st_as_sf(sites, coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32643) # add an outline of the nilgiris shapefile (contains areas below 1400 m) nil &lt;- st_read(&quot;data/landcover/Nil_Ana_Pal.shp&quot;) nil &lt;- nil[2, ] nil &lt;- st_transform(nil, 32643) buffer &lt;- st_buffer(nil, 3e4) %&gt;% st_transform(4326) # add the elevation raster alt &lt;- rast(&quot;data/elevation/alt/&quot;) # this layer is not added to github as a result of its large size and can be downloaded from SRTM (Farr et al. (2007)) alt.hills &lt;- terra::crop(alt, as(buffer, &quot;Spatial&quot;)) rm(alt) gc() # get slope and aspect slopeData &lt;- terrain(x = alt.hills, v = c(&quot;slope&quot;, &quot;aspect&quot;)) # use c() on terra object to combine as a stack elevData &lt;- c(alt.hills, slopeData) rm(alt.hills) gc() 6.4 Load the climate rasters Note that there are four rasters: temperature and precipitation for both dry season and rainy season respectively. The dry season refers to the months of December to May while the rainy season refers to the months of June to November. Each raster corresponds to mean monthly value across a single decade (1870-1890 and so on). In other words, ppt_dry_1870 would refer to the mean monthly precipitation between December to May for the time-period 1870 to 1880. # use previously loaded climate reconstruction data climate_reconstructed # crop each reconstruction to the previously prepared buffer # and transform/assign the crs of the site data climate_reconst_nilgiris &lt;- map( climate_reconstructed, function(cl) { cl &lt;- terra::project(cl, crs(sites)) } ) # extract the above data for each of the resurvye locations # use explicit namespacing of extract from terra, i.e., terra::extract climate_reconst_sites &lt;- lapply(climate_reconst_nilgiris, function(cl) { terra::extract(cl, as(sites, &quot;SpatVector&quot;)) }) # extract elevation, aspect, slope at sites # first transform elevation data to UTM 43N terrain_nilgiris &lt;- terra::project(elevData, crs(sites)) terrain_sites &lt;- terra::extract(terrain_nilgiris, as(sites, &quot;SpatVector&quot;)) 6.5 Combine site climate and terrain data # merge all extracted climate data at sites climate_reconst_sites &lt;- reduce(climate_reconst_sites, left_join) # now convert to long format climate_reconst_sites &lt;- pivot_longer( climate_reconst_sites, cols = !ID, names_to = &quot;climate_measure&quot; ) # split season and year column climate_reconst_sites &lt;- separate_wider_regex( climate_reconst_sites, cols = climate_measure, patterns = c( climate_measure = &quot;.*&quot;, &quot;_&quot;, season = &quot;dry|rainy&quot;, &quot;_&quot;, year = &quot;\\\\d{4}&quot; ) ) # join with terrain data clim_terrain_sites &lt;- left_join( climate_reconst_sites, terrain_sites ) # add site data - first drop sites &lt;- st_drop_geometry(sites) %&gt;% mutate(ID = seq(nrow(sites))) %&gt;% as_tibble() # join with site data clim_terrain_sites &lt;- left_join( clim_terrain_sites, sites ) # make factors numerics clim_terrain_sites &lt;- mutate( clim_terrain_sites, year = as.numeric(year), alt = as.numeric(as.character(alt)) ) # save climate at sites readr::write_csv( clim_terrain_sites, &quot;data/results/clim_terrain_sites.csv&quot; ) 6.6 Plot all reconstructed climate over time colouring by elevation and grouping by site. Each line represents one modern site code. ggplot( clim_terrain_sites, aes( x = year, y = value, col = alt, group = modern_site_code ) ) + geom_line( position = position_jitter(width = 0.2) ) + scale_colour_binned_sequential( palette = &quot;Batlow&quot; ) + facet_grid( rows = vars(climate_measure), cols = vars(season), scales = &quot;free_y&quot;, labeller = label_both ) + labs( colour = &quot;Elev. (m)&quot; ) ggsave( filename = &quot;figs/fig_clim_reconst_site_elev.png&quot;, dpi = 150 ) Reconstructed climate as a function of elevation across the last century 6.7 Alternative figure for temperature change over time # get the mean proportional change in climate variables at sites # binned by elevation (200m bins), separated by season clim_prop_change &lt;- clim_terrain_sites %&gt;% mutate( elev_bin = plyr::round_any(alt, 200) ) %&gt;% group_by( climate_measure, season, modern_site_code, elev_bin ) %&gt;% mutate( prop_change = (value - first(value)) / first(value) ) # nest by climate variable for more visible colour scales clim_prop_change &lt;- ungroup(clim_prop_change) %&gt;% nest(.by = &quot;climate_measure&quot;) # function for plotting fn_plot &lt;- function(df) { ggplot(df) + stat_summary_2d( aes(as.factor(year), as.factor(elev_bin), z = prop_change), col = &quot;grey&quot;, linewidth = 0.1 ) + facet_grid( cols = vars(season), labeller = labeller( season = c( dry = &quot;Dry&quot;, rainy = &quot;Rainy&quot; ) ) ) + scale_fill_continuous_diverging( palette = &quot;Blue-Red 2&quot;, labels = function(x) { scales::percent(x) } ) + theme_bw() + theme( legend.position = &quot;top&quot;, legend.key.height = unit(3, &quot;mm&quot;), legend.key.width = unit(20, &quot;mm&quot;), axis.text.x = element_text( angle = 45, hjust = 0.75 ) ) + labs( x = &quot;Decade&quot;, y = &quot;Elevation bin (m)&quot;, fill = &quot;Difference (%)&quot; ) } clim_prop_change &lt;- mutate( clim_prop_change, plots = map(data, fn_plot) ) # save plots walk2( clim_prop_change$plots, clim_prop_change$climate_measure, function(x, y) { ggsave( x, filename = glue(&quot;figs/fig_elev_bin_{y}_change.png&quot;), height = 4, width = 7, dpi = 300 ) } ) Differences in mean monthly temperatures between the earliest decade and future decades revealed ~10% difference in temperatures across elevations over time 6.8 Test for climate change over time Run a GLMM for the value over time, with measure, season, historical site code, and modern land cover type as random effects. All terrain covariates are fixed effects, and time is the main fixed effect of interest. Save/report this model fit. # set site code and landcover as factors clim_terrain_sites$historical_site_code &lt;- as.factor(clim_terrain_sites$historical_site_code) clim_terrain_sites$modern_landCover_type &lt;- as.factor(clim_terrain_sites$modern_landCover_type) # split by measure clim_terrain_sites &lt;- nest( clim_terrain_sites, .by = climate_measure ) # run model clim_terrain_sites &lt;- mutate( clim_terrain_sites, model_fit = map( data, function(df) { gam( value ~ year + alt + slope + aspect + season + s(historical_site_code, bs = &quot;re&quot;) + s(modern_landCover_type, bs = &quot;re&quot;), data = df ) } ) ) map(clim_terrain_sites$model_fit, summary) "],["land-cover-classification-and-change-detection.html", "Section 7 Land cover classification and change detection 7.1 Load necessary libraries 7.2 Processing digitized shapefiles from the 1848 map 7.3 Rasterization of the 1848 shapefiles 7.4 Load the 2018 satellite image 7.5 Subsume plantations into one category for 2018 7.6 Write the shapefiles and rasters to file 7.7 Area-wise comparisons of land cover change 7.8 Barplots of land cover change 7.9 Validating the 2018 Sentinel-2 classification", " Section 7 Land cover classification and change detection In this script, we will process land cover polygons and rasters for multiple time periods (1848 and 2018) across the Nilgiri hills of the Western Ghats biodiversity hotspot. For the year 1848, a survey map (created by Captain John Ouchterlony) was obtained from the British Library and the Tamil Nadu State Archive and was manually digitized to arrive at multiple land cover classes (for more information on the process of digitization, please read the accompanying manuscript and use the READMe section in the GitHub repository). For the year 2018, we relied on satellite imagery from Sentinel-2 (the imagery was classified using Google Earth Engine and more information on the classification can be obtained below). 7.1 Load necessary libraries library(sf) library(raster) library(terra) library(tmap) library(stars) library(dplyr) library(tidyverse) library(mapview) library(landscapemetrics) library(scico) library(extrafont) library(exactextractr) 7.2 Processing digitized shapefiles from the 1848 map We will be loading shapefiles that were digitized by Amrutha Rajan for the 1848 historical map. # list all shapefiles in the directory nil1848 &lt;- list.files(&quot;data/landcover/1848-nilgiris/&quot;, full.names = T, recursive = T, pattern = &quot;.shp$&quot;) # create vector files ag1848 &lt;- st_read(nil1848[1]) # type: multipolygon; 6 empty geometries noData1848 &lt;- st_read(nil1848[2]) # type: multipolygon plantations1848 &lt;- st_read(nil1848[3]) # type: polygon &amp; multipolygon; 1 empty geometry roads1848 &lt;- st_read(nil1848[4]) # type: linestring settlements1848 &lt;- st_read(nil1848[5]) # type: polygon &amp; multipolygon; 3 geometries empty sholaForest1848 &lt;- st_read(nil1848[6]) # type: polygon &amp; multippolygon; 6 geometries empty sholaGrassland1848 &lt;- st_read(nil1848[7]) # type: multipolygon swamps1848 &lt;- st_read(nil1848[8]) # type: polygon &amp; multipolygon; eight geometries are empty waterBodies1848 &lt;- st_read(nil1848[9]) # type: multipolygon # explore and fix any issues with the above vector files # we need to ensure consistency across files for the sake of merging them into a single geometry collection # we notice a range of small issues with the shapefiles above # the geometry type is variable and needs to be consistent # empty geometries need to be removed # attribute names need to be consistent across shapefiles # first, we will remove empty geometries ag1848 &lt;- ag1848[!st_is_empty(ag1848), ] noData1848 &lt;- noData1848[!st_is_empty(noData1848), ] plantations1848 &lt;- plantations1848[!st_is_empty(plantations1848), ] roads1848 &lt;- roads1848[!st_is_empty(roads1848), ] settlements1848 &lt;- settlements1848[!st_is_empty(settlements1848), ] sholaForest1848 &lt;- sholaForest1848[!st_is_empty(sholaForest1848), ] sholaGrassland1848 &lt;- sholaGrassland1848[!st_is_empty(sholaGrassland1848), ] swamps1848 &lt;- swamps1848[!st_is_empty(swamps1848), ] waterBodies1848 &lt;- waterBodies1848[!st_is_empty(waterBodies1848), ] # fixing attribute tables to ensure they are consistent across shapefiles names(ag1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) ag1848$name &lt;- &quot;agriculture&quot; names(noData1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) noData1848$name &lt;- &quot;no_data&quot; names(plantations1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) plantations1848$name &lt;- &quot;plantations&quot; names(roads1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) roads1848$name &lt;- &quot;roads&quot; names(settlements1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) settlements1848$name &lt;- &quot;settlements&quot; names(sholaForest1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) sholaForest1848$name &lt;- &quot;shola_forest&quot; names(sholaGrassland1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) sholaGrassland1848$name &lt;- &quot;shola_grassland&quot; names(swamps1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) swamps1848$name &lt;- &quot;swamps&quot; names(waterBodies1848) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) waterBodies1848$name &lt;- &quot;water_bodies&quot; # Note: the roads shapefile is a linestring while the other geometry types are polygon/multipolygon # transform to UTM 43N ag1848 &lt;- st_transform(ag1848, 32643) noData1848 &lt;- st_transform(noData1848, 32643) plantations1848 &lt;- st_transform(plantations1848, 32643) roads1848 &lt;- st_transform(roads1848, 32643) settlements1848 &lt;- st_transform(settlements1848, 32643) sholaForest1848 &lt;- st_transform(sholaForest1848, 32643) sholaGrassland1848 &lt;- st_transform(sholaGrassland1848, 32643) swamps1848 &lt;- st_transform(swamps1848, 32643) waterBodies1848 &lt;- st_transform(waterBodies1848, 32643) # creating a single simple feature collection nil1848 &lt;- rbind( ag1848, plantations1848, settlements1848, sholaForest1848, sholaGrassland1848, swamps1848, waterBodies1848 ) # subsuming swamps under grasslands nil1848 &lt;- nil1848 %&gt;% mutate(name = case_when( name == &quot;swamps&quot; ~ &quot;shola_grassland&quot;, .default = as.character(name) )) # crop the 1848 shapefiles to within the 1400m contour only nil1848 &lt;- st_buffer(nil1848, dist = 0) nil1848 &lt;- nil1848[, -c(3:5)] # Create a common boundary for clipping files from another time period (2018)(see below) all1848 &lt;- st_buffer(st_union(nil1848), dist = 0) 7.3 Rasterization of the 1848 shapefiles The 1848 digitized shapefiles are rasterized for comparison with the 2018 sentinel satellite imagery. # nil11848 raster # scale: 1000ft to 1 inch (1:12000; 6 metres resolution) # This link was used for reference to convert from map scale to raster pixel resolution: https://www.esri.com/arcgis-blog/products/product/imagery/on-map-scale-and-raster-resolution/ vect1848 &lt;- terra::vect(nil1848) emptyRast &lt;- terra::rast(res = 6, xmin = 660555.3, xmax = 719135.5, ymin = 1240050, ymax = 1277597, crs = &quot;+proj=utm +zone=43 +datum=WGS84 +units=m +no_defs&quot;) rast1848 &lt;- terra::rasterize(vect1848, emptyRast, &quot;name&quot;) 7.4 Load the 2018 satellite image The 2018 satellite image was obtained from Sentinel-2. Cloud-free days (1% cloud cover) were chosen from March 2018 and a composite was created. We then utilized groundtruthing points from [@arasumani2019] and used a Random Forests classifier (n = 1000 trees; Kappa statistic = 93.9%, overall accuracy of 94.8% was obtained on test data) to obtain a classified image with seven land cover classes (similar to the 1848 map). For more details on the classification, please visit this link: https://code.earthengine.google.com/49e2de4f9cd84c8587fc0596d3d5aec3 ## load the raster rast2018 &lt;- terra::rast(&quot;data/landcover/2018-nilgiris/2018.tif&quot;) values(rast2018)[values(rast2018) &lt;= 0] &lt;- NA ## convert the raster to a categorical raster rast2018 &lt;- as.factor(rast2018) ## set land cover class names to the 2018 raster ## note: this was done carefully by examining the values associated ## with each number from classification process (done in GEE) ## create a dataframe with names of classes and their corresponding values landcover_class &lt;- data.frame( ID = 1:7, name = c( &quot;agriculture&quot;, &quot;shola_forest&quot;, &quot;shola_grassland&quot;, &quot;timber_plantations&quot;, &quot;settlements&quot;, &quot;tea_plantations&quot;, &quot;water_bodies&quot; ) ) levels(rast2018) &lt;- landcover_class ## resample the 1848 raster to the 2018 raster to match spatial res ## The 1848 raster is at 6 m resolution ## The 2018 raster is at 10 m resolution rast1848 &lt;- resample(rast1848, rast2018, method = &quot;near&quot;) # visualization of the two rasters colors2018 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # timber plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#04a310&quot;, # tea plantations, light green &quot;#2035df&quot; # waterbodies, royal blue ) ## side-by-side visualization colors1848 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#c17111&quot;, # plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#2035df&quot; # waterbodies, royal blue ) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_1848_vs_2018.png&quot;, width = 12, height = 7, units = &quot;in&quot;, res = 300 ) par(mfrow = c(1, 2)) plot(rast1848, col = colors1848, main = &quot;1848&quot;, legend = FALSE ) plot(rast2018, col = colors2018, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_class$name, fill = colors2018, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() 7.5 Subsume plantations into one category for 2018 Since 1848 had very few to no tea plantations and only timber plantations were present at the time, we reclassify timber plantations into the plantations category for the 2018 raster to ease comparisons. # read reclassification matrix reclassification_matrix &lt;- read.csv(&quot;data/landcover/2018-nilgiris/reclassification-matrix.csv&quot;) reclassification_matrix &lt;- as.matrix(reclassification_matrix[, c(&quot;V1&quot;, &quot;To&quot;)]) # reclassification rast2018_reclassified &lt;- terra::classify( x = rast2018, rcl = reclassification_matrix ) ## create a dataframe with names of classes and their corresponding values landcover_reclass &lt;- data.frame( ID = 1:6, name = c( &quot;agriculture&quot;, &quot;shola_forest&quot;, &quot;shola_grassland&quot;, &quot;plantations&quot;, &quot;settlements&quot;, &quot;water_bodies&quot; ) ) levels(rast2018_reclassified) &lt;- landcover_reclass ## side-by-side visualization colors2018reclass &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#2035df&quot; # waterbodies, royal blue ) png( filename = &quot;figs/fig_landCover_1848_vs_2018reclassified.png&quot;, width = 12, height = 7, units = &quot;in&quot;, res = 300 ) par(mfrow = c(1, 2)) plot(rast1848, col = colors1848, main = &quot;1848&quot;, legend = FALSE ) plot(rast2018_reclassified, col = colors2018reclass, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_reclass$name, fill = colors2018reclass, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() Landcover change between 1848 and 2018 7.6 Write the shapefiles and rasters to file Please note that the processed rasters above have been resampled to a resolution of 10 metres. # vectors st_write(nil1848, &quot;results/landcover/1848.shp&quot;, driver = &quot;ESRI Shapefile&quot; ) # rasters terra::writeRaster(rast1848, &quot;results/landcover/1848.tif&quot;) terra::writeRaster(rast2018, &quot;results/landcover/2018.tif&quot;) terra::writeRaster(rast2018_reclassified, &quot;results/landcover/2018reclassified.tif&quot;) 7.7 Area-wise comparisons of land cover change # area-wise calculations for the 2018 raster (the below objects will be used to compare overall areas, alongside the 1848 map) sz2018 &lt;- cellSize(rast2018, unit = &quot;m&quot;) area2018 &lt;- zonal(sz2018, rast2018, sum) area2018SqKm &lt;- (area2018$area / 1000000) area2018 &lt;- cbind(area2018, area2018SqKm) # area-wise calculations for the 2018 reclassified raster (the below objects will be used to compare overall areas, alongside the 1848 map) sz2018_reclass &lt;- cellSize(rast2018_reclassified, unit = &quot;m&quot;) area2018_reclass &lt;- zonal(sz2018_reclass, rast2018_reclassified, sum) area2018SqKm_reclass &lt;- (area2018_reclass$area / 1000000) area2018_reclass &lt;- cbind(area2018_reclass, area2018SqKm_reclass) # area-wise calculations for the 1848 raster (the below objects will be used to compare overall areas, alongside the 2018 sentinel satellite image) sz1848 &lt;- cellSize(rast1848, unit = &quot;m&quot;) area1848 &lt;- zonal(sz1848, rast1848, sum) area1848SqKm &lt;- (area1848$area / 1000000) area1848 &lt;- cbind(area1848, area1848SqKm) 7.8 Barplots of land cover change # Joining all dataframes to create a single one for plotting and visualization names(area1848) &lt;- c(&quot;class&quot;, &quot;areaInMeters&quot;, &quot;sumArea&quot;) names(area2018) &lt;- c(&quot;class&quot;, &quot;areaInMeters&quot;, &quot;sumArea&quot;) areaCalc &lt;- purrr::reduce(list( area1848, area2018 ), dplyr::full_join, by = &quot;class&quot;) names(areaCalc) &lt;- c(&quot;class&quot;, &quot;areaMt1848&quot;, &quot;1848&quot;, &quot;areaMt2018&quot;, &quot;2018&quot;) areaCalc &lt;- areaCalc %&gt;% dplyr::select(&quot;class&quot;, &quot;1848&quot;, &quot;2018&quot;) %&gt;% pivot_longer(!class, names_to = &quot;Year&quot;, values_to = &quot;Area&quot;) # since the 1848 map had timber and tea plantations subsumed and the 2018 had it separated, we will manually edit the same areaCalc &lt;- areaCalc %&gt;% drop_na() write.csv(areaCalc, &quot;results/totalArea-by-landCover-timePeriod.csv&quot;, row.names = F) # make plot fig_area &lt;- ggplot(areaCalc, aes( x = class, y = Area, fill = class )) + geom_bar( stat = &quot;identity&quot;, position = position_dodge() ) + scale_fill_manual(values = c( &quot;#be4fc4&quot;, &quot;#d73027&quot;, &quot;#b0a69d&quot;, &quot;#025a05&quot;, &quot;#cbb315&quot;, &quot;#04a310&quot;, &quot;#c17111&quot;, &quot;#2035df&quot; )) + geom_text( aes( label = round(Area), hjust = &quot;middle&quot;, vjust = -0.5 ), family = &quot;Century Gothic&quot;, position = position_dodge(), angle = 0, size = 5 ) + facet_wrap(~Year, scales = &quot;free_x&quot;) + theme_bw() + labs( x = &quot;\\nLand cover type&quot;, y = &quot;Area in sq.km. \\n&quot; ) + theme( text = element_text(size = 14, family = &quot;Century Gothic&quot;), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = &quot;none&quot; ) ggsave(fig_area, filename = &quot;figs/fig_totalArea_landCover.png&quot;, width = 15, height = 13, device = png(), units = &quot;in&quot;, dpi = 600 ) dev.off() # get percentArea occupied by each land cover class percentArea &lt;- areaCalc %&gt;% group_by(Year) %&gt;% mutate( totalArea = sum(Area, na.rm = T), percentArea = (Area / totalArea) * 100 ) # plot figure fig_percent_area &lt;- ggplot(percentArea, aes(x = class, y = percentArea, fill = class)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge()) + scale_fill_manual(values = c( &quot;#be4fc4&quot;, &quot;#d73027&quot;, &quot;#b0a69d&quot;, &quot;#025a05&quot;, &quot;#cbb315&quot;, &quot;#04a310&quot;, &quot;#c17111&quot;, &quot;#2035df&quot; )) + geom_text(aes(label = round(percentArea, digits = 1), hjust = &quot;middle&quot;, vjust = -0.5), position = position_dodge(), family = &quot;Century Gothic&quot;, angle = 0, size = 5) + facet_wrap(~Year, scales = &quot;free_x&quot;) + theme_bw() + labs( x = &quot;\\nLand cover type&quot;, y = &quot;Percent Area \\n&quot; ) + theme( text = element_text(size = 14, family = &quot;Century Gothic&quot;), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = &quot;none&quot; ) ggsave(fig_percent_area, filename = &quot;figs/fig_percentArea_landCover.png&quot;, width = 14, height = 13, device = png(), units = &quot;in&quot;, dpi = 500) dev.off() Barplots of change in area of each land cover class between 1848 and 2018 7.9 Validating the 2018 Sentinel-2 classification In the above classification, we see an increase in forest cover of ~ 132 sq.km between 1848 and 2018. However, is the 2018 classification accurate? Can we compare these estimates to an existing land cover classification from 2017? nil2017 &lt;- st_read(&quot;data/landcover/2017-nilgiris/2017.shp&quot;) nil2017 &lt;- st_intersection(nil2017, all1848) # Let&#39;s add class name to nil2017 shapefile nil2017 &lt;- nil2017 %&gt;% mutate(name = case_when( gridcode == 1 ~ &quot;shola_grassland&quot;, gridcode == 2 ~ &quot;shola_forest&quot;, gridcode == 3 ~ &quot;timber_plantations&quot;, gridcode == 4 ~ &quot;tea_plantations&quot;, gridcode == 6 ~ &quot;settlements&quot;, gridcode == 7 ~ &quot;agriculture&quot;, gridcode == 8 ~ &quot;water_bodies&quot; )) # remove older column nil2017 &lt;- nil2017[, -3] # renaming for ease of visualization names(nil2017) &lt;- c(&quot;id&quot;, &quot;area&quot;, &quot;geometry&quot;, &quot;name&quot;) ## note that the spatial resolution of Landsat is at 30 m spatial resolution vect2017 &lt;- terra::vect(nil2017) emptyRast &lt;- terra::rast(res = 30, xmin = 660750, xmax = 718329, ymin = 1240554, ymax = 1275510, crs = &quot;+proj=utm +zone=43 +datum=WGS84 +units=m +no_defs&quot;) rast2017 &lt;- terra::rasterize(vect2017, emptyRast, &quot;name&quot;) # resample the 2018 raster to 30m rast2018 &lt;- resample(rast2018, rast2017, method = &quot;near&quot;) # mask the 2018 raster with the 2017 one since the 2017 raster was only for area above 1400m rast2018 &lt;- mask(rast2018, rast2017) # visualizing the two classifications colors2017 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#04a310&quot;, # tea plantations, light green &quot;#c17111&quot;, # timber plantations, brownish &quot;#2035df&quot; # waterbodies, royal blue ) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_2018_vs_2017.png&quot;, width = 12, height = 7, units = &quot;in&quot;, res = 300 ) par(mfrow = c(1, 2)) plot(rast2018, col = colors2018, main = &quot;2018 Sentinel classification&quot;, legend = FALSE ) plot(rast2017, col = colors2017, main = &quot;2017 Landsat classification&quot;, legend = FALSE) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_class$name, fill = colors2018, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() ## area-wise calculations sz2018 &lt;- cellSize(rast2018, unit = &quot;m&quot;) area2018 &lt;- zonal(sz2018, rast2018, sum) area2018SqKm &lt;- (area2018$area / 1000000) area2018 &lt;- cbind(area2018, area2018SqKm) sz2017 &lt;- cellSize(rast2017, unit = &quot;m&quot;) area2017 &lt;- zonal(sz2017, rast2017, sum) area2017SqKm &lt;- (area2017$area / 1000000) area2017 &lt;- cbind(area2017, area2017SqKm) # Joining all dataframes to create a single one for plotting and visualization names(area2017) &lt;- c(&quot;class&quot;, &quot;areaInMeters&quot;, &quot;sumArea&quot;) names(area2018) &lt;- c(&quot;class&quot;, &quot;areaInMeters&quot;, &quot;sumArea&quot;) areaCalc &lt;- purrr::reduce(list( area2017, area2018 ), dplyr::full_join, by = &quot;class&quot;) names(areaCalc) &lt;- c(&quot;class&quot;, &quot;areaMt2017&quot;, &quot;2017&quot;, &quot;areaMt2018&quot;, &quot;2018&quot;) areaCalc &lt;- areaCalc %&gt;% dplyr::select(&quot;class&quot;, &quot;2017&quot;, &quot;2018&quot;) %&gt;% pivot_longer(!class, names_to = &quot;Year&quot;, values_to = &quot;Area&quot;) write.csv(areaCalc, &quot;results/totalArea-by-landCover-2018-vs-2017.csv&quot;, row.names = F) Comparing the 2018 Sentinel classification to the 2017 Landsat classification of the same area revealed no major differences "],["grassland-contractions-forest-expansions.html", "Section 8 Grassland contractions &amp; forest expansions 8.1 Load necessary libraries 8.2 Load processed land cover rasters 8.3 Visualize forests across the two time periods 8.4 Visualize grassland area across the two time periods 8.5 Comparing if forests have increased in locations where grasslands were formerly found? 8.6 Have forests expanded across elevations? 8.7 How do grassland patches vary by elevation across time periods? 8.8 Comparing if plantations have increased in locations where grasslands were formerly found?", " Section 8 Grassland contractions &amp; forest expansions In the previous script, we inferred that grasslands have contracted dramatically, plantations have increased drastically and forests have expanded as well. In this script, we will compare and contrasts areas where forests and plantations have increased over time and if these areas overlap with grassland habitats (in the past). 8.1 Load necessary libraries library(sf) library(raster) library(terra) library(dplyr) library(tidyverse) library(mapview) library(scico) library(extrafont) library(ggstatsplot) 8.2 Load processed land cover rasters rast1848 &lt;- terra::rast(&quot;results/landcover/1848.tif&quot;) rast2018 &lt;- terra::rast(&quot;results/landcover/2018reclassified.tif&quot;) 8.3 Visualize forests across the two time periods ## saving a high resolution visualization png( filename = &quot;figs/fig_forests_1848_vs_2018.png&quot;, width = 12, height = 7, units = &quot;in&quot;, res = 300 ) par(mfrow = c(1, 2)) plot(rast1848 == &quot;shola_forest&quot;, main = &quot;1848 forest cover&quot;, legend = FALSE ) plot(rast2018 == &quot;shola_forest&quot;, main = &quot;2018 forest cover&quot;, legend = FALSE ) dev.off() Forest cover differences between 1848 and 2018 8.4 Visualize grassland area across the two time periods ## saving a high resolution visualization png( filename = &quot;figs/fig_grasslands_1848_vs_2018.png&quot;, width = 12, height = 7, units = &quot;in&quot;, res = 300 ) par(mfrow = c(1, 2)) plot(rast1848 == &quot;shola_grassland&quot;, main = &quot;1848 grassland cover&quot;, legend = FALSE ) plot(rast2018 == &quot;shola_grassland&quot;, main = &quot;2018 grassland cover&quot;, legend = FALSE ) dev.off() Comparing grassland areas between 1848 and 2018 8.5 Comparing if forests have increased in locations where grasslands were formerly found? # first, we will polygonize the rasters vect1848 &lt;- st_as_sf(as.polygons(rast1848)) vect2018 &lt;- st_as_sf(as.polygons(rast2018)) # add a year column to the polygons vect1848$year &lt;- &quot;1848&quot; vect2018$year &lt;- &quot;2018&quot; # overlay shola_forests from 2018 over shola_grasslands from 1848 # first, we will interactively view the visualization grass1848 &lt;- mapview(vect1848[vect1848$name == &quot;shola_grassland&quot;, ], col.regions = &quot;#cbb315&quot;) for2018 &lt;- mapview(vect2018[vect2018$name == &quot;shola_forest&quot;, ], col.regions = &quot;#04a310&quot;, alpha.regions = 0.5 ) map_vis &lt;- grass1848 + for2018 ## save the interactive visualization html_fl &lt;- tempfile(tmpdir = getwd(), fileext = &quot;.html&quot;) # create standalone .html mapview::mapshot(map_vis, url = html_fl) # clearly the above analyses reveals that large number of areas that were formerly grasslands in 1848 are now forests in 2018. # producing a static visualization grass1848 &lt;- vect1848[vect1848$name == &quot;shola_grassland&quot;, ] for2018 &lt;- vect2018[vect2018$name == &quot;shola_forest&quot;, ] fig_for2018_grass1848 &lt;- ggplot() + geom_sf(data = grass1848, fill = &quot;#cbb315&quot;) + geom_sf(data = for2018, fill = &quot;#04a310&quot;) + facet_wrap(name ~ year) + theme_bw() + theme( text = element_text(size = 14, family = &quot;Century Gothic&quot;), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = &quot;none&quot; ) ggsave(fig_for2018_grass1848, filename = &quot;figs/fig_forests2018_vs_grasslands1848.png&quot;, width = 22, height = 8, device = png(), units = &quot;in&quot;, dpi = 600 ) dev.off() Several areas across the landscape that were formerly grasslands in 1848 are now forests in 2018 8.6 Have forests expanded across elevations? In the above visualizations, we observed that forests have expanded across areas that were formerly grasslands. We ask if these expansions vary as a function of elevation. In other words, are forests expanding upslope? # add elevation raster # adding a higher resolution DEM from ALOS alt &lt;- rast(&quot;data/elevation/alos-elevation-30m.tif&quot;) # this layer is not added to github as a result of its large size and can be downloaded from SRTM (Farr et al. (2007)) # use shapefile to crop the elevation raster outline &lt;- st_transform(vect1848, 4326) alt.hills &lt;- terra::crop(alt, outline) # transform to wgs84 to extract elev vect1848poly &lt;- st_transform(vect1848, 4326) vect2018poly &lt;- st_transform(vect2018, 4326) ## convert data from multipolygon to polygon vect1848poly &lt;- st_cast(vect1848poly, &quot;POLYGON&quot;) vect2018poly &lt;- st_cast(vect2018poly, &quot;POLYGON&quot;) # extract values from that raster (note: transformation of coordinate system) # we will extract minimum, mean and maximum elevation from polygon objects # for 1848 data elevMin &lt;- terra::extract(alt.hills, vect1848poly, fun = min, na.rm = T ) elevMean &lt;- terra::extract(alt.hills, vect1848poly, fun = mean, na.rm = TRUE ) elevMax &lt;- terra::extract(alt.hills, vect1848poly, fun = max, na.rm = TRUE ) names(elevMin) &lt;- c(&quot;ID&quot;, &quot;elevMin&quot;) names(elevMean) &lt;- c(&quot;ID&quot;, &quot;elevMean&quot;) names(elevMax) &lt;- c(&quot;ID&quot;, &quot;elevMax&quot;) vect1848poly &lt;- cbind( vect1848poly, elevMin[, -1], elevMean[, -1], elevMax[, -1] ) names(vect1848poly) &lt;- c( &quot;name&quot;, &quot;year&quot;, &quot;elevMin&quot;, &quot;elevMean&quot;, &quot;elevMax&quot;, &quot;geometry&quot; ) # for 2018 data # please note: despite using terra functions, the following lines of code take ~ 3-5 minutes of time elevMin &lt;- terra::extract(alt.hills, vect2018poly, fun = min, na.rm = TRUE ) elevMean &lt;- terra::extract(alt.hills, vect2018poly, fun = mean, na.rm = TRUE ) elevMax &lt;- raster::extract(alt.hills, vect2018poly, fun = max, na.rm = TRUE ) names(elevMin) &lt;- c(&quot;ID&quot;, &quot;elevMin&quot;) names(elevMean) &lt;- c(&quot;ID&quot;, &quot;elevMean&quot;) names(elevMax) &lt;- c(&quot;ID&quot;, &quot;elevMax&quot;) vect2018poly &lt;- cbind( vect2018poly, elevMin[, -1], elevMean[, -1], elevMax[, -1] ) names(vect2018poly) &lt;- c( &quot;name&quot;, &quot;year&quot;, &quot;elevMin&quot;, &quot;elevMean&quot;, &quot;elevMax&quot;, &quot;geometry&quot; ) # visualization gc() elev1848 &lt;- vect1848poly %&gt;% st_drop_geometry() elev2018 &lt;- vect2018poly %&gt;% st_drop_geometry() data_for_plotting &lt;- bind_rows( elev1848, elev2018 ) write.csv(data_for_plotting, &quot;results/elevation-landCover-overTime.csv&quot;, row.names = F ) # get only forest data data_forest &lt;- data_for_plotting %&gt;% filter(name == &quot;shola_forest&quot;) # has minimum elevation increased over time? fig_forest_minElev &lt;- ggbetweenstats( data = data_forest, x = year, y = elevMin, xlab = &quot;Time Period&quot;, ylab = &quot;Minimum elevation in meters&quot;, title = &quot;Minimum elevation across which shola forest patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_forest_minElev, filename = &quot;figs/fig_sholaForests_minimumElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() # has mean elevation increased over time? fig_forest_meanElev &lt;- ggbetweenstats( data = data_forest, x = year, y = elevMean, xlab = &quot;Time Period&quot;, ylab = &quot;Mean elevation in meters&quot;, title = &quot;Mean elevation across which shola forest patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_forest_meanElev, filename = &quot;figs/fig_sholaForests_meanElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() ## significant differences were observed in mean elevation across time periods, with mean elevation of shola forests being significantly lower in modern time periods compared to historical time periods fig_forest_maxElev &lt;- ggbetweenstats( data = data_forest, x = year, y = elevMax, xlab = &quot;Time Period&quot;, ylab = &quot;Max elevation in meters&quot;, title = &quot;Max elevation across which shola forest patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_forest_maxElev, filename = &quot;figs/fig_sholaForests_maxElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Mean elevation of shola forest patches in 1848 vs.Â 2018 suggests a significant decrease in elevation in the modern era 8.7 How do grassland patches vary by elevation across time periods? data_grassland &lt;- data_for_plotting %&gt;% # get only grasslands filter(name == &quot;shola_grassland&quot;) # has minimum elevation increased over time? fig_grassland_minElev &lt;- ggbetweenstats( data = data_grassland, x = year, y = elevMin, xlab = &quot;Time Period&quot;, ylab = &quot;Minimum elevation in meters&quot;, title = &quot;Minimum elevation across which shola grassland patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_grassland_minElev, filename = &quot;figs/fig_sholaGrasslands_minimumElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() # has mean elevation increased over time? fig_grassland_meanElev &lt;- ggbetweenstats( data = data_grassland, x = year, y = elevMean, xlab = &quot;Time Period&quot;, ylab = &quot;Mean elevation in meters&quot;, title = &quot;Mean elevation across which shola grassland patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_grassland_meanElev, filename = &quot;figs/fig_sholaGrasslands_meanElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() fig_grassland_maxElev &lt;- ggbetweenstats( data = data_grassland, x = year, y = elevMax, xlab = &quot;Time Period&quot;, ylab = &quot;Max elevation in meters&quot;, title = &quot;Max elevation across which shola grassland patches occurred in 1848 and 2018&quot;, plot.type = &quot;box&quot;, pairwise.comparisons = T ) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_grassland_maxElev, filename = &quot;figs/fig_sholaGrasslands_maxElevation.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Comparison of mean elevation of grassland patches between 1848 and 2018 revealed a significant decline in elevation in the modern era 8.8 Comparing if plantations have increased in locations where grasslands were formerly found? # overlay plantations from 2018 over shola_grasslands from 1848 # first, we will interactively view the visualization grass1848 &lt;- mapview(vect1848[vect1848$name == &quot;shola_grassland&quot;, ], col.regions = &quot;#cbb315&quot;) plant2018 &lt;- mapview(vect2018[vect2018$name == &quot;plantations&quot;, ], col.regions = &quot;#c17111&quot;, alpha.regions = 0.5) map_vis &lt;- grass1848 + plant2018 ## save the interactive visualization html_fl &lt;- tempfile(tmpdir = getwd(), fileext = &quot;.html&quot;) # create standalone .html mapview::mapshot(map_vis, url = html_fl) # producing a static visualization grass1848 &lt;- vect1848[vect1848$name == &quot;shola_grassland&quot;, ] plant2018 &lt;- vect2018[vect2018$name == &quot;plantations&quot;, ] fig_plant2018_grass1848 &lt;- ggplot() + geom_sf(data = grass1848, fill = &quot;#cbb315&quot;) + geom_sf(data = plant2018, fill = &quot;#c17111&quot;) + facet_wrap(name ~ year) + theme_bw() + theme( text = element_text(size = 14, family = &quot;Century Gothic&quot;), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = &quot;none&quot; ) ggsave(fig_plant2018_grass1848, filename = &quot;figs/fig_plantations2018_vs_grasslands1848.png&quot;, width = 22, height = 8, device = png(), units = &quot;in&quot;, dpi = 600 ) dev.off() Interactive visualizations of forests in 2018 and grasslands in 1848 can be accessed via Zenodo (the files are very large for a GitHub upload). "],["visualizing-time-series-of-change.html", "Section 9 Visualizing time series of change 9.1 Load necessary libraries 9.2 Load processed land cover rasters 9.3 Loading data from the 1910 map 9.4 Rasterizing of the 1910 data 9.5 Loading the 1973 and 1995 data 9.6 Rasterization of the 1973 and 1995 data 9.7 Visualization of landscape change over time 9.8 Subsume plantations into one category for 1973, 1995, and 2018 9.9 Creating smaller regions of interest for comparison 9.10 Comparisons only above 1400 meters in elevation", " Section 9 Visualizing time series of change From our previous visualizations, one could potentially attribute changes in grassland area in 2018 to expansion of forests and plantations over time. However, our interpretations are restricted to simply two time points over time. Here, we include the addition of data from three intermediate time periods: 1910 (Survey of India map that is partially digitized), 1973 and 1995 (the latter two are published maps from @arasumani2019). 9.1 Load necessary libraries library(sf) library(raster) library(terra) library(stars) library(dplyr) library(tidyverse) library(mapview) library(landscapemetrics) library(scico) library(extrafont) 9.2 Load processed land cover rasters rast1848 &lt;- terra::rast(&quot;results/landcover/1848.tif&quot;) rast2018 &lt;- terra::rast(&quot;results/landcover/2018.tif&quot;) 9.3 Loading data from the 1910 map # list all shapefiles in the directory nil1910 &lt;- list.files(&quot;data/landcover/1910-nilgiris/&quot;, full.names = T, recursive = T, pattern = &quot;.shp$&quot;) # create vector files ag1910 &lt;- st_read(nil1910[1]) # type: multipolygon plantations1910 &lt;- st_read(nil1910[2]) # type: multipolygon; 1 empty geometry settlements1910 &lt;- st_read(nil1910[3]) # type: polygon sholaForest1910 &lt;- st_read(nil1910[4]) # type: multipolygon sholaGrassland1910 &lt;- st_read(nil1910[5]) # type: multipolygon waterBodies1910 &lt;- st_read(nil1910[6]) # type: polygon # explore and fix any issues with the above vector files # we need to ensure consistency across files for the sake of merging them into a single geometry collection # we notice a range of small issues with the shapefiles above # the geometry type is variable and needs to be consistent # empty geometries need to be removed # attribute names need to be consistent across shapefiles # first, we will remove empty geometries plantations1910 &lt;- plantations1910[!st_is_empty(plantations1910), ] # fixing attribute tables to ensure they are consistent across shapefiles ag1910 &lt;- ag1910[, -3] plantations1910 &lt;- plantations1910[, -3] settlements1910 &lt;- settlements1910[, -3] sholaForest1910 &lt;- sholaForest1910[, -3] sholaGrassland1910 &lt;- sholaGrassland1910[, -3] waterBodies1910 &lt;- waterBodies1910[, -3] names(ag1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) ag1910$name &lt;- &quot;agriculture&quot; names(plantations1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) plantations1910$name &lt;- &quot;plantations&quot; names(settlements1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) settlements1910$name &lt;- &quot;settlements&quot; names(sholaForest1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) sholaForest1910$name &lt;- &quot;shola_forest&quot; names(sholaGrassland1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) sholaGrassland1910$name &lt;- &quot;shola_grassland&quot; names(waterBodies1910) &lt;- c(&quot;id&quot;, &quot;name&quot;, &quot;geometry&quot;) waterBodies1910$name &lt;- &quot;water_bodies&quot; # transform to UTM 43N ag1910 &lt;- st_transform(ag1910, 32643) plantations1910 &lt;- st_transform(plantations1910, 32643) settlements1910 &lt;- st_transform(settlements1910, 32643) sholaForest1910 &lt;- st_transform(sholaForest1910, 32643) sholaGrassland1910 &lt;- st_transform(sholaGrassland1910, 32643) waterBodies1910 &lt;- st_transform(waterBodies1910, 32643) # creating a single simple feature collection nil1910 &lt;- rbind(ag1910, plantations1910, settlements1910, sholaForest1910, sholaGrassland1910, waterBodies1910) 9.4 Rasterizing of the 1910 data # rasterize # the scale of the map is 1:63360 ~30 m pixel size for rasterization vect1910 &lt;- terra::vect(nil1910) emptyRast &lt;- terra::rast(res = 30, xmin = 656316.3, xmax = 726964.6, ymin = 1229234, ymax = 1281983, crs = &quot;+proj=utm +zone=43 +datum=WGS84 +units=m +no_defs&quot;) rast1910 &lt;- terra::rasterize(vect1910, emptyRast, &quot;name&quot;) ## we need to mask the raster with the 1848 raster ## we use terra::mask as there are empty/no_data values in 1848 ## prior to masking, we need to crop and reset extents ## note, we are resetting the extent to match the 1848 raster rast1910 &lt;- crop(rast1910, rast1848) ## extents still do not match for masking ## force set extents ext(rast1910) &lt;- c(660555.3, 719133.3, 1240050, 1277598) ## We have one other issue to tackle before we mask ## The nrow and ncols do not match because of differences in spatial res ## resample the 1848 and the 2018 rasters to the 1910 rasters to match spatial resolution ## The 1848 raster and 2018 rasters is at 10 m resolution rast1848 &lt;- resample(rast1848, rast1910, method = &quot;near&quot;) rast2018 &lt;- resample(rast2018, rast1910, method = &quot;near&quot;) ## masking the 1910 raster with the 1848 raster rast1910 &lt;- mask(rast1910, rast1848) ## convert the raster to a categorical raster rast1910 &lt;- as.factor(rast1910) ## create a dataframe with names of classes and their corresponding values landcover_reclass &lt;- data.frame( ID = 0:5, name = c( &quot;agriculture&quot;, &quot;plantations&quot;, &quot;settlements&quot;, &quot;shola_forest&quot;, &quot;shola_grassland&quot;, &quot;water_bodies&quot; ) ) levels(rast1910) &lt;- landcover_reclass 9.5 Loading the 1973 and 1995 data # load the 1973 and 1995 shapefiles nil1973 &lt;- st_read(&quot;data/landcover/1973-nilgiris/1973.shp&quot;) nil1995 &lt;- st_read(&quot;data/landcover/1995-nilgiris/1995.shp&quot;) # Let&#39;s first add class name to nil1973 shapefile nil1973 &lt;- nil1973 %&gt;% mutate(name = case_when( gridcode == 1 ~ &quot;shola_grassland&quot;, gridcode == 2 ~ &quot;shola_forest&quot;, gridcode == 3 ~ &quot;timber_plantations&quot;, gridcode == 4 ~ &quot;tea_plantations&quot;, gridcode == 5 ~ &quot;ochlandra&quot;, gridcode == 6 ~ &quot;settlements&quot;, gridcode == 7 ~ &quot;agriculture&quot;, gridcode == 8 ~ &quot;water_bodies&quot; )) # Let&#39;s add class name to nil1995 shapefile nil1995 &lt;- nil1995 %&gt;% mutate(name = case_when( gridcode == 1 ~ &quot;shola_grassland&quot;, gridcode == 2 ~ &quot;shola_forest&quot;, gridcode == 3 ~ &quot;timber_plantations&quot;, gridcode == 4 ~ &quot;tea_plantations&quot;, gridcode == 5 ~ &quot;ochlandra&quot;, gridcode == 6 ~ &quot;settlements&quot;, gridcode == 7 ~ &quot;agriculture&quot;, gridcode == 8 ~ &quot;water_bodies&quot; )) # renaming for ease of visualization names(nil1973) &lt;- c(&quot;id&quot;, &quot;area&quot;, &quot;geometry&quot;, &quot;name&quot;) names(nil1995) &lt;- c(&quot;id&quot;, &quot;area&quot;, &quot;geometry&quot;, &quot;name&quot;) 9.6 Rasterization of the 1973 and 1995 data # rasterize vect1973 &lt;- terra::vect(nil1973) emptyRast &lt;- terra::rast(res = 30, xmin = 517079.8, xmax = 794369.8, ymin = 922564.6, ymax = 1500035, crs = &quot;+proj=utm +zone=43 +datum=WGS84 +units=m +no_defs&quot;) rast1973 &lt;- terra::rasterize(vect1973, emptyRast, &quot;name&quot;) ## crop and mask to the 1848 raster rast1973 &lt;- crop(rast1973, rast1848) ## extents still do not match for masking ## force set extents ext(rast1973) &lt;- c(660555.3, 719133.3, 1240050, 1277598) ## resample the 1848, 1910 &amp; 2018 rasters to the 1973 rasters to match spatial resolution rast1848 &lt;- resample(rast1848, rast1973, method = &quot;near&quot;) rast1910 &lt;- resample(rast1910, rast1973, method = &quot;near&quot;) rast2018 &lt;- resample(rast2018, rast1973, method = &quot;near&quot;) ## masking the 1973 raster with the 1848 raster rast1973 &lt;- mask(rast1973, rast1848) ## convert the raster to a categorical raster rast1973 &lt;- as.factor(rast1973) ## create a dataframe with names of classes and their corresponding values landcover_class &lt;- data.frame( ID = c(0, 2:7), name = c( &quot;agriculture&quot;, &quot;settlements&quot;, &quot;shola_forest&quot;, &quot;shola_grassland&quot;, &quot;tea_plantations&quot;, &quot;timber_plantations&quot;, &quot;water_bodies&quot; ) ) levels(rast1973) &lt;- landcover_class # repeating process for 1995 data # note that the spatial resolution of Landsat TM is at 30 m spatial resolution vect1995 &lt;- terra::vect(nil1995) emptyRast &lt;- terra::rast(res = 30, xmin = 517079.8, xmax = 794369.8, ymin = 922564.6, ymax = 1500035, crs = &quot;+proj=utm +zone=43 +datum=WGS84 +units=m +no_defs&quot;) rast1995 &lt;- terra::rasterize(vect1995, emptyRast, &quot;name&quot;) ## crop and mask to the 1848 raster rast1995 &lt;- crop(rast1995, rast1848) ## extents still do not match for masking ## force set extents ext(rast1995) &lt;- c(660555.3, 719133.3, 1240050, 1277598) # resample raster from 1995 to match resolution of 1973 raster rast1995 &lt;- resample(rast1995, rast1973, method = &quot;near&quot;) ## masking the 1995 raster with the 1848 raster rast1995 &lt;- mask(rast1995, rast1848) ## convert the raster to a categorical raster rast1995 &lt;- as.factor(rast1995) levels(rast1995) &lt;- landcover_class 9.7 Visualization of landscape change over time ## side-by-side visualization colors1848 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#c17111&quot;, # plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#2035df&quot; # waterbodies, royal blue ) colors1973 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#04a310&quot;, # tea plantations, light green &quot;#c17111&quot;, # timber plantations, brownish &quot;#2035df&quot; # waterbodies, royal blue ) colors2018 &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # timber plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#04a310&quot;, # tea plantations, light green &quot;#2035df&quot; # waterbodies, royal blue ) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_timeSeries.png&quot;, width = 15, height = 10, units = &quot;in&quot;, res = 300 ) par(mfrow = c(2, 3)) plot(rast1848, col = colors1848, main = &quot;1848&quot;, legend = FALSE ) plot(rast1910, col = colors1848, main = &quot;1910&quot;, legend = FALSE ) plot(rast1973, col = colors1973, main = &quot;1973&quot;, legend = FALSE ) plot(rast1995, col = colors1973, main = &quot;1995&quot;, legend = FALSE ) plot(rast2018, col = colors2018, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_class$name, fill = colors1973, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() Landscape change over time with the inclusion of data across 1848, 1910, 1973, 1995 and 2018 revealed similar conclusions as before 9.8 Subsume plantations into one category for 1973, 1995, and 2018 Since 1848 had very few to no tea plantations and only timber plantations were present at the time, we reclassify timber plantations into the plantations category for the 1973, 1995 and 2018 rasters to ease comparisons. # load existing reclassified 2018 raster rast2018 &lt;- terra::rast(&quot;results/landcover/2018reclassified.tif&quot;) rast2018 &lt;- resample(rast2018, rast1973, method = &quot;near&quot;) # read reclassification matrix reclassification_matrix &lt;- read.csv(&quot;data/landcover/1973-nilgiris/reclassification-matrix.csv&quot;) reclassification_matrix &lt;- as.matrix(reclassification_matrix[, c(&quot;V1&quot;, &quot;To&quot;)]) # reclassification rast1973_reclassified &lt;- terra::classify( x = rast1973, rcl = reclassification_matrix ) rast1995_reclassified &lt;- terra::classify( x = rast1995, rcl = reclassification_matrix ) ## create a dataframe with names of classes and their corresponding values landcover_reclass &lt;- data.frame( ID = 1:6, name = c( &quot;agriculture&quot;, &quot;settlements&quot;, &quot;shola_forest&quot;, &quot;shola_grassland&quot;, &quot;plantations&quot;, &quot;water_bodies&quot; ) ) levels(rast1973_reclassified) &lt;- landcover_reclass levels(rast1995_reclassified) &lt;- landcover_reclass ## side-by-side visualization colors1973reclass &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # plantations, brownish &quot;#2035df&quot; # waterbodies, royal blue ) colors2018reclass &lt;- c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # plantations, brownish &quot;#b0a69d&quot;, # settlements, grayish &quot;#2035df&quot; # waterbodies, royal blue ) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_timeSeries_reclassified.png&quot;, width = 15, height = 10, units = &quot;in&quot;, res = 300 ) par(mfrow = c(2, 3)) plot(rast1848, col = colors1848, main = &quot;1848&quot;, legend = FALSE ) plot(rast1910, col = colors1848, main = &quot;1910&quot;, legend = FALSE ) plot(rast1973_reclassified, col = colors1973reclass, main = &quot;1973&quot;, legend = FALSE) plot(rast1995_reclassified, col = colors1973reclass, main = &quot;1995&quot;, legend = FALSE) plot(rast2018, col = colors2018reclass, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_reclass$name, fill = colors1973reclass, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() Landscape change over time with tea plantations and timber plantations subsumed into a single category 9.9 Creating smaller regions of interest for comparison While comparing a time series of landscape change shows how different land cover types have expanded or contracted over time, the broader regions of interest are slightly different across time periods. Here, I subset rasters by cropping smaller extents, prior to visualization. ## south-western quadrant sw1848 &lt;- crop(rast1848, c( 666000, 675000, 1240050, 1255000 )) sw1910 &lt;- crop(rast1910, c( 666000, 675000, 1240050, 1255000 )) sw1973 &lt;- crop(rast1973_reclassified, c( 666000, 675000, 1240050, 1255000 )) sw1995 &lt;- crop(rast1995_reclassified, c( 666000, 675000, 1240050, 1255000 )) sw2018 &lt;- crop(rast2018, c( 666000, 675000, 1240050, 1255000 )) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_timeSeries_southWesternRegion.png&quot;, width = 15, height = 10, units = &quot;in&quot;, res = 300 ) par(mfrow = c(2, 3)) plot(sw1848, col = c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#2035df&quot; # waterbodies, royal blue ), main = &quot;1848&quot;, legend = FALSE) plot(sw1910, col = c( &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#2035df&quot; # waterbodies, royal blue ), main = &quot;1910&quot;, legend = FALSE) plot(sw1973, col = c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # plantations, brownish &quot;#2035df&quot; # waterbodies, royal blue ), main = &quot;1973&quot;, legend = FALSE) plot(sw1995, col = c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#c17111&quot;, # plantations, brownish &quot;#2035df&quot; # waterbodies, royal blue ), main = &quot;1995&quot;, legend = FALSE) plot(sw2018, col = colors2018reclass, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_reclass$name, fill = colors1973reclass, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() # western quadrant w1848 &lt;- crop(rast1848, c( 665000, 680000, 1255000, 1265000 )) w1910 &lt;- crop(rast1910, c( 665000, 680000, 1255000, 1265000 )) w1973 &lt;- crop(rast1973_reclassified, c( 665000, 680000, 1255000, 1265000 )) w1995 &lt;- crop(rast1995_reclassified, c( 665000, 680000, 1255000, 1265000 )) w2018 &lt;- crop(rast2018, c( 665000, 680000, 1255000, 1265000 )) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_timeSeries_westernRegion.png&quot;, width = 15, height = 10, units = &quot;in&quot;, res = 300 ) par(mfrow = c(2, 3)) plot(w1848, col = c( &quot;#be4fc4&quot;, # agriculture, violetish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot; # shola grasslands, yellowish ), main = &quot;1848&quot;, legend = FALSE) plot(w1910, col = c( &quot;#be4fc4&quot;, &quot;#b0a69d&quot;, # settlements, grayish &quot;#025a05&quot;, # shola forests, dark green &quot;#cbb315&quot;, # shola grasslands, yellowish &quot;#2035df&quot; # waterbodies, royal blue ), main = &quot;1910&quot;, legend = FALSE) plot(w1973, col = colors1973reclass, main = &quot;1973&quot;, legend = FALSE) plot(w1995, col = colors1973reclass, main = &quot;1995&quot;, legend = FALSE) plot(w2018, col = colors2018reclass, main = &quot;2018&quot;, legend = FALSE ) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_reclass$name, fill = colors1973reclass, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() Comparing changes across the south-western quandrant of the map over time Comparing changes across the western Nilgiris over time 9.10 Comparisons only above 1400 meters in elevation Here, we use the 1973/1995 raster as masks to restrict region of comparisons to only above 1400 meters in elevation # creating high elevation rasters/regions of interest rast1848high &lt;- mask(rast1848, rast1973_reclassified) rast1910high &lt;- mask(rast1910, rast1973_reclassified) rast2018high &lt;- mask(rast2018, rast1973_reclassified) ## saving a high resolution visualization png( filename = &quot;figs/fig_landCover_timeSeries_above1400meters.png&quot;, width = 15, height = 10, units = &quot;in&quot;, res = 300 ) par(mfrow = c(2, 3)) plot(rast1848high, col = colors1848, main = &quot;1848&quot;, legend = FALSE ) plot(rast1910high, col = colors1848, main = &quot;1910&quot;, legend = FALSE ) plot(rast1973_reclassified, col = colors1973reclass, main = &quot;1973&quot;, legend = FALSE) plot(rast1995_reclassified, col = colors1973reclass, main = &quot;1995&quot;, legend = FALSE) plot(rast2018high, col = colors2018reclass, main = &quot;2018&quot;, legend = FALSE) # add custom legend par( mar = c(0, 0, 0, 0), new = TRUE ) plot(0, 0, type = &quot;l&quot;, bty = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) legend(&quot;bottom&quot;, legend = landcover_reclass$name, fill = colors1973reclass, cex = 0.8, title = &quot;land cover classes&quot;, ncol = 2 ) dev.off() Comparing data above 1400 meters along revealed a similar result of grassland loss and forest increase "],["exploratory-analysis-of-occurrence-data.html", "Section 10 Exploratory analysis of occurrence data 10.1 Load necessary libraries 10.2 Load the historical occurrence data and explore patterns 10.3 Examining historical data by locality 10.4 Visualizations of historical data 10.5 Examining species specific counts by locality 10.6 Load modern occurrence data and explore patterns", " Section 10 Exploratory analysis of occurrence data This script carries out exploratory analysis of historical and modern occurrence data from the Nilgiri hills. 10.1 Load necessary libraries library(dplyr) library(stringr) library(tidyverse) library(scico) library(RColorBrewer) library(extrafont) 10.2 Load the historical occurrence data and explore patterns The historical occurrence data is a combination of data from museum specimens and those observations made in published literature/journals (titled journal data). We apply the following key filters on this dataset prior to carrying out further exploratory analyses: a) we subset historical data to only include specimen information until the year 1950 and b) we excluded historical sampling locations that had very few records (total specimen data &lt; 10). hist_occ &lt;- read.csv(&quot;data/historical-occurrence-data.csv&quot;) # after exploring the data, we will apply the following filters on the dataset # a: include only data until 1950 hist_occ &lt;- hist_occ %&gt;% filter(year &lt;= 1950) # b: a second filter includes only those species that had a minimum count of atleast three specimens and occurred across atleast two unique historical survey locations # total species count across historical data spp_count &lt;- hist_occ %&gt;% group_by(scientific_name, common_name) %&gt;% count() # total of 179 species sppMinThree &lt;- spp_count %&gt;% filter(n &gt;= 3) # total of 92 species # please note, we include ~four species that were collected from a single historical location Apus melba, Apus melba, Brachypodius priocephalus, Phylloscopus tytleri, Picus chlorolophus # filter historical data hist_occ &lt;- hist_occ %&gt;% filter(scientific_name %in% sppMinThree$scientific_name) # count of data by year occ_year &lt;- hist_occ %&gt;% group_by(year) %&gt;% count() # The above count suggests that majority of the bird specimens were recorded in 1881, followed by some data from 1876. collector &lt;- hist_occ %&gt;% group_by(collectedBy) %&gt;% count() # 37 unique collectors/ornithologists who collected museum specimens in this time period, with the maximum number of records by William Davison, followed by R G Wardlaw-Ramsay. 10.3 Examining historical data by locality # Twenty unique historical site localities across which species were recorded occ_locality &lt;- hist_occ %&gt;% group_by(historical_site_code) %&gt;% count() ## OTCM had the highest number of specimens (~674) while RNMD had the lowest (1 specimen) # Examining species by locality spp_loc &lt;- hist_occ %&gt;% group_by(common_name, historical_site_code) %&gt;% count() # how many unique sites prop_count &lt;- spp_loc %&gt;% group_by(common_name) %&gt;% summarise(uniqueSites = length(unique(historical_site_code))) 10.4 Visualizations of historical data fig_loc_timePeriod &lt;- ggplot(occ_locality, aes(x = reorder(historical_site_code, -n), y = n, fill = historical_site_code)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge(), fill = &quot;#883107&quot;, alpha = 0.9) + geom_text(aes(label = n, hjust = &quot;middle&quot;, vjust = -0.5), position = position_dodge(), angle = 0, size = 5 ) + theme_bw() + labs( x = &quot;\\nLocality&quot;, y = &quot;Count\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text(family = &quot;Century Gothic&quot;, size = 14), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.position = &quot;none&quot; ) ggsave(fig_loc_timePeriod, filename = &quot;figs/fig_histCount_locality.png&quot;, width = 12, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() A count of historical occurrence data across resurvey locations 10.5 Examining species specific counts by locality fig_spp &lt;- ggplot(spp_count, aes(x = reorder(common_name, -n), y = n, fill = scientific_name)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge(), fill = &quot;#883107&quot;, alpha = 0.9) + geom_text(aes(label = n, hjust = &quot;middle&quot;, vjust = -0.5), position = position_dodge(), angle = 0, size = 5 ) + theme_bw() + labs( x = &quot;\\nSpecies&quot;, y = &quot;Count\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text(family = &quot;Century Gothic&quot;, size = 14), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.position = &quot;none&quot; ) ggsave(fig_spp, filename = &quot;figs/fig_histSpp.png&quot;, width = 50, height = 20, device = png(), units = &quot;in&quot;, dpi = 300, limitsize = F) dev.off() Species-specific counts of historical data across resurvey locations 10.6 Load modern occurrence data and explore patterns # note, we are only including those species that were reported in the historical data # this is mainly done to avoid artificial increases in abundance in the modern time period mod_occ &lt;- read.csv(&quot;data/modern-occurrence-data.csv&quot;) %&gt;% filter(!is.na(historical_site_code)) # 2301 observations of 103 bird species # ensure the data is comparable with historical data mod_occ &lt;- mod_occ %&gt;% filter(!is.na(species_code)) %&gt;% filter(common_name %in% hist_occ$common_name) %&gt;% filter(historical_site_code %in% hist_occ$historical_site_code) # total observations of species in the modern surveys modOcc_spp &lt;- mod_occ %&gt;% group_by(common_name) %&gt;% count() # 63 bird species that were common to modern &amp; historical # plot figure of species by locality mod_occ_loc &lt;- mod_occ %&gt;% group_by(common_name, historical_site_code) %&gt;% count() # figure of species by locality fig_modSpp_loc &lt;- ggplot(mod_occ_loc, aes(x = reorder(historical_site_code, -n), y = n, fill = historical_site_code)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge(), fill = &quot;#883107&quot;, alpha = 0.9) + geom_text(aes(label = n, hjust = &quot;middle&quot;, vjust = -0.5), position = position_dodge(), angle = 0, size = 5 ) + facet_wrap(~common_name) + theme_bw() + labs( x = &quot;\\nSpecies and Locality&quot;, y = &quot;Count\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text(family = &quot;Century Gothic&quot;, size = 12), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.position = &quot;none&quot; ) ggsave(fig_modSpp_loc, filename = &quot;figs/fig_modSpp_loc.png&quot;, width = 40, height = 17, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() ## Some interesting patterns of certain species being more abundant/detected in certain sites over others. Modern occurrence data of species across resurvey locations "],["species-relative-abundances-over-time.html", "Section 11 Species relative abundances over time 11.1 Load necessary libraries 11.2 Load list of resurvey locations 11.3 Calibrating historical data to modern survey data for relative abundance calculations 11.4 Calculating species relative abundance for the historical data (1850-1900 and 1900-1950) 11.5 Load the modern occurrence data 11.6 Calculate dirichlet distributions of relative abundance 11.7 Boxplot visualization of overall relative abundance across time periods 11.8 Species relative abundances at the site-level 11.9 Visualizing differences in relative abundance over time at the site level 11.10 Writing results to file", " Section 11 Species relative abundances over time In this script, we calculate species relative abundances over time by replicating a novel approach proposed by Gotelli et al.Â 2021 (who provides a methodological approach to calculate relative species abundances using historical museum records). The assumption is that the level of the analysis is at the â€˜historic-siteâ€™ and not the â€˜modern-siteâ€™ (which essentially corresponds to multiple unique modern survey sites for every â€˜historic-siteâ€™). 11.1 Load necessary libraries library(dplyr) library(stringr) library(tidyverse) library(scico) library(RColorBrewer) library(extrafont) library(sf) library(raster) library(lattice) library(data.table) library(ggrepel) library(report) library(lme4) library(glmmTMB) library(multcomp) library(ggstatsplot) library(paletteer) library(ggpubr) library(goeveg) library(sjPlot) library(patchwork) # source custom functions source(&quot;code/02_relative-species-abundance-functions.R&quot;) 11.2 Load list of resurvey locations We will load the list of sites across which a modern resurvey was carried out, along with elevation rasters. # load list of resurvey locations and add elevation as a variable # remove the modern resurvey locations only (ie. ASFQ) sites &lt;- read.csv(&quot;data/list-of-resurvey-locations.csv&quot;) sites &lt;- sites[-c(1:50), ] # convert to sf object and transform sites &lt;- st_as_sf(sites, coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32643) # add elevation raster alt &lt;- raster::raster(&quot;data/elevation/alt&quot;) # this layer is not added to github as a result of its large size and can be downloaded from SRTM (Farr et al. (2007)) # extract values from that raster (note: transformation of coordinate system) elev &lt;- raster::extract(alt, sites) sites &lt;- cbind(sites, elev) 11.3 Calibrating historical data to modern survey data for relative abundance calculations To ensure that museum specimens and associated observations are comparable with field associated surveys, since they are both independent sources of information, we calibrate them to understand if they are comparable in the first place. ## read in historical occurrence data hist_occ &lt;- read.csv(&quot;data/historical-occurrence-data.csv&quot;) ## applying filters: # include only data until 1950 hist_occ &lt;- hist_occ %&gt;% filter(year &lt;= 1950) # total species count across historical data spp_count &lt;- hist_occ %&gt;% group_by(scientific_name, common_name) %&gt;% count() # total of 179 species sppMinThree &lt;- spp_count %&gt;% filter(n &gt;= 3) # total of 92 species ## read in modern occurrence data mod_occ &lt;- read.csv(&quot;data/modern-occurrence-data.csv&quot;) %&gt;% filter(!is.na(historical_site_code)) # 2301 observations of 103 bird species # ensure the data is comparable with historical data mod_occ &lt;- mod_occ %&gt;% filter(!is.na(species_code)) %&gt;% filter(common_name %in% hist_occ$common_name) %&gt;% filter(historical_site_code %in% hist_occ$historical_site_code) # total species count across historical data mod_spp_count &lt;- mod_occ %&gt;% group_by(common_name) %&gt;% count() ## group by scientific name and modern site code mod_occ &lt;- mod_occ %&gt;% filter(!is.na(common_name)) %&gt;% group_by(common_name, modern_site_code) %&gt;% summarise(&quot;2021&quot; = sum(number)) ## left join the sites dataframe mod_occ &lt;- left_join(mod_occ, sites, by = c(&quot;modern_site_code&quot; = &quot;modern_site_code&quot;)) %&gt;% filter(!is.na(common_name)) %&gt;% replace(is.na(.), 0) # calculate total count of historical data at each site # here we pool all historical data from 1850-1950 hist_occ_tot &lt;- hist_occ %&gt;% group_by(common_name, historical_site_code) %&gt;% count() %&gt;% summarise(&quot;historical&quot; = sum(n)) # left join the sites dataframe hist_occ_tot &lt;- left_join(hist_occ_tot, sites, by = c(&quot;historical_site_code&quot; = &quot;historical_site_code&quot;)) %&gt;% filter(!is.na(common_name)) %&gt;% replace(is.na(.), 0) # we remove modern site_code and get only distinct rows unique_hist &lt;- hist_occ_tot[, c(1, 2, 3)] %&gt;% group_by(common_name, historical_site_code) %&gt;% distinct() %&gt;% group_by(common_name) %&gt;% summarise(&quot;relAbundHist&quot; = sum(historical)) # we remove modern site_code and get only distinct rows unique_mod &lt;- mod_occ[, c(1, 3, 5)] %&gt;% group_by(common_name, historical_site_code) %&gt;% distinct() %&gt;% group_by(common_name) %&gt;% summarise(&quot;relAbund2021&quot; = sum(`2021`)) # join historical and modern dataframes hist_mod &lt;- full_join(unique_hist, unique_mod) %&gt;% replace_na(list( relAbundHist = 0, relAbund2021 = 0 )) # apply dirichlet distribution to the historical data # choosing 1850-1900 data first dat &lt;- tibble::deframe(hist_mod[, 1:2]) relAbunHist &lt;- dirch_stats(dat) %&gt;% dplyr::select(species, bayes_mean) %&gt;% rename(., bayes_mean_hist = bayes_mean) # apply dirichlet distribution to the modern survey dat &lt;- tibble::deframe(hist_mod[, c(1, 3)]) ## choosing modern data relAbun2021 &lt;- dirch_stats(dat) %&gt;% dplyr::select(species, bayes_mean) %&gt;% rename(., bayes_mean_2021 = bayes_mean) # for calibration ### join the relative abundance datasets together relAbunCalib &lt;- full_join(relAbunHist, relAbun2021) %&gt;% arrange(species) %&gt;% rename(., &quot;historical&quot; = &quot;bayes_mean_hist&quot;) %&gt;% rename(., &quot;modern&quot; = &quot;bayes_mean_2021&quot;) %&gt;% rename(., common_name = species) # regressing 1850-1950 data vs. 2021 fig_hist_v_mod_rel &lt;- ggplot(data = relAbunCalib, aes(x = modern, y = historical)) + scale_y_log10() + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;) + scale_x_log10() + labs( y = &quot;Historical Relative abundance&quot;, x = &quot;Modern Relative abundance&quot; ) + geom_point(shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 2, stroke = 1) + geom_smooth(method = &quot;lm&quot;, se = TRUE, fullrange = FALSE, level = 0.95, linetype = &quot;solid&quot;) + stat_regline_equation(aes(label = ..rr.label..)) + # geom_text_repel(aes(label = common_name),family = &quot;Century Gothic&quot;, fontface = &quot;italic&quot;) + theme_bw() + theme( axis.text = element_text(family = &quot;Century Gothic&quot;, size = 13), legend.title = element_text(family = &quot;Century Gothic&quot;), legend.text = element_text(family = &quot;Century Gothic&quot;), text = element_text(family = &quot;Century Gothic&quot;, size = 25) ) ggsave(fig_hist_v_mod_rel, filename = &quot;figs/fig_historical_vs_modern_relAbun.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Historical vs.Â modern species relative abundance suggests high correlations, implying that they are comparable to one another 11.4 Calculating species relative abundance for the historical data (1850-1900 and 1900-1950) ## read in historical occurrence data hist_occ &lt;- read.csv(&quot;data/historical-occurrence-data.csv&quot;) ## applying filters: # a: include only data until 1950 hist_occ &lt;- hist_occ %&gt;% filter(year &lt;= 1950) # b: a second filter includes only those species that had a minimum count of atleast three specimens and occurred across atleast two unique historical survey locations # total species count across historical data spp_count &lt;- hist_occ %&gt;% group_by(common_name) %&gt;% count() # total of 179 species sppMinThree &lt;- spp_count %&gt;% filter(n &gt;= 3) # please note, we include ~four species that were collected from a single historical location Apus melba, Apus melba, Brachypodius priocephalus, Phylloscopus tytleri, Picus chlorolophus # filter historical data hist_occ &lt;- hist_occ %&gt;% filter(common_name %in% sppMinThree$common_name) ### pre-1900 hist_occ_pre1900 &lt;- hist_occ %&gt;% filter(year &lt;= 1900) # calculate total count of historical data at each site hist_occ_pre1900 &lt;- hist_occ_pre1900 %&gt;% group_by(common_name, historical_site_code) %&gt;% count() %&gt;% summarise(&quot;1850-1900&quot; = sum(n)) # left join the sites dataframe hist_occ_pre1900 &lt;- left_join(hist_occ_pre1900, sites, by = c(&quot;historical_site_code&quot; = &quot;historical_site_code&quot;)) %&gt;% filter(!is.na(common_name)) %&gt;% replace(is.na(.), 0) ## 1900-1950 data hist_occ_1900_1950 &lt;- hist_occ %&gt;% filter(year &gt; 1900 &amp; year &lt;= 1950) # calculate total count of historical data at each site hist_occ_1900_1950 &lt;- hist_occ_1900_1950 %&gt;% group_by(common_name, historical_site_code) %&gt;% count() %&gt;% summarise(&quot;1900-1950&quot; = sum(n)) # left join the sites dataframe hist_occ_1900_1950 &lt;- left_join(hist_occ_1900_1950, sites, by = c(&quot;historical_site_code&quot; = &quot;historical_site_code&quot;)) %&gt;% filter(!is.na(common_name)) %&gt;% replace(is.na(.), 0) 11.5 Load the modern occurrence data For the modern occurrence data, we only keep species that were recorded historically to avoid artificial increases in relative abundance due to the method of collection. mod_occ &lt;- read.csv(&quot;data/modern-occurrence-data.csv&quot;) %&gt;% filter(!is.na(historical_site_code)) # 2301 observations of 103 bird species # ensure the data is comparable with historical data mod_occ &lt;- mod_occ %&gt;% filter(!is.na(species_code)) %&gt;% filter(common_name %in% hist_occ$common_name) %&gt;% filter(historical_site_code %in% hist_occ$historical_site_code) # total species count across historical data mod_spp_count &lt;- mod_occ %&gt;% group_by(common_name) %&gt;% count() # total of 63 spp ## group by scientific name and modern site code mod_occ &lt;- mod_occ %&gt;% filter(!is.na(common_name)) %&gt;% group_by(common_name, modern_site_code) %&gt;% summarise(&quot;2021&quot; = sum(number)) ## left join the sites dataframe mod_occ &lt;- left_join(mod_occ, sites, by = c(&quot;modern_site_code&quot; = &quot;modern_site_code&quot;)) %&gt;% filter(!is.na(common_name)) %&gt;% replace(is.na(.), 0) 11.6 Calculate dirichlet distributions of relative abundance Here, we will functions from Gotelli et al.Â 2023 to calculate relative species abundances between historic and modern periods. # note: the level of the analysis is at the &#39;historic-site&#39; and not the &#39;modern-site&#39; (which essentially corresponds to two or three unique sites for every &#39;historic-site&#39;) # to ensure that the analysis is consistent, we sum abundances across the modern sites corresponding to each historic site # However, our analysis calculates relative species abundances for the give time period rather than by site + time-period # we remove modern site_code and get only distinct rows unique_hist_pre1900 &lt;- hist_occ_pre1900[, c(1, 2, 3)] %&gt;% group_by(common_name, historical_site_code) %&gt;% distinct() %&gt;% group_by(common_name) %&gt;% summarise(&quot;relAbund1850&quot; = sum(`1850-1900`)) # we remove modern site_code and get only distinct rows unique_hist_1900_1950 &lt;- hist_occ_1900_1950[, c(1, 2, 3)] %&gt;% group_by(common_name, historical_site_code) %&gt;% distinct() %&gt;% group_by(common_name) %&gt;% summarise(&quot;relAbund1900&quot; = sum(`1900-1950`)) # we remove modern site_code and get only distinct rows unique_mod &lt;- mod_occ[, c(1, 3, 5)] %&gt;% group_by(common_name, historical_site_code) %&gt;% distinct() %&gt;% group_by(common_name) %&gt;% summarise(&quot;relAbund2021&quot; = sum(`2021`)) hist_mod &lt;- full_join( unique_hist_pre1900, unique_hist_1900_1950 ) %&gt;% full_join(., unique_mod) %&gt;% replace_na(list( relAbund1850 = 0, relAbund1900 = 0, relAbund2021 = 0 )) # apply dirichlet distribution to the historical data # choosing 1850-1900 data first dat &lt;- tibble::deframe(hist_mod[, 1:2]) relAbun1850 &lt;- dirch_stats(dat) %&gt;% dplyr::select(species, bayes_mean) %&gt;% rename(., bayes_mean_1850 = bayes_mean) # choosing 1900-1950 data dat &lt;- tibble::deframe(hist_mod[, c(1, 3)]) relAbun1900 &lt;- dirch_stats(dat) %&gt;% dplyr::select(species, bayes_mean) %&gt;% rename(., bayes_mean_1900 = bayes_mean) # apply dirichlet distribution to the modern survey dat &lt;- tibble::deframe(hist_mod[, c(1, 4)]) ## choosing modern data relAbun2021 &lt;- dirch_stats(dat) %&gt;% dplyr::select(species, bayes_mean) %&gt;% rename(., bayes_mean_2021 = bayes_mean) ### join the relative abundance datasets together relAbun &lt;- full_join(relAbun1850, relAbun1900) %&gt;% full_join(., relAbun2021) %&gt;% arrange(species) %&gt;% rename(., `1850-1900` = &quot;bayes_mean_1850&quot;) %&gt;% rename(., `1900-1950` = &quot;bayes_mean_1900&quot;) %&gt;% rename(., `2021` = &quot;bayes_mean_2021&quot;) %&gt;% rename(., common_name = species) 11.7 Boxplot visualization of overall relative abundance across time periods data_for_boxplot &lt;- relAbun %&gt;% dplyr::select(-common_name) %&gt;% pivot_longer(everything()) fig_relAbun_over_time &lt;- ggbetweenstats( data = data_for_boxplot, x = name, y = value, xlab = &quot;Time Period&quot;, ylab = &quot;Relative Abundance&quot;, title = &quot;Relative abundance by time period&quot;, violin.args = list(width = 0), pairwise.comparisons = T ) + scale_y_log10() + # scale_color_manual(values = c(&quot;#9EB0FFFF&quot;, &quot;#122C39FF&quot;,&quot;#D5857DFF&quot;)) + theme( plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 16, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 14 ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ) ) ggsave(fig_relAbun_over_time, filename = &quot;figs/fig_relAbun_landscapeLevel.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Species relative abundance over time (pooled at the landscape level) 11.8 Species relative abundances at the site-level We now recalculate species relative abundances at the site-level, which will be used for downstream comparisons with change in land cover and climate at a given site. # 1850-1900 data # we remove modern site_code and get only distinct rows hist_pre1900 &lt;- hist_occ_pre1900[, c(1:3)] %&gt;% distinct(.) # 1900-1950 data # we remove modern site_code and get only distinct rows hist_1900_1950 &lt;- hist_occ_1900_1950[, c(1:3)] %&gt;% distinct(.) ## modern resurvey ## analysis is being done at the level of the historical site code mod_site_level &lt;- mod_occ[, c(1, 3, 5)] %&gt;% group_by(common_name, historical_site_code) %&gt;% mutate(&quot;2021&quot; = sum(`2021`)) %&gt;% distinct(.) ## join data frames together site_level_relAbun &lt;- full_join( hist_pre1900, hist_1900_1950 ) %&gt;% full_join(., mod_site_level) %&gt;% replace_na(list( `1850-1900` = 0, `1900-1950` = 0, `2021` = 0 )) %&gt;% ungroup() %&gt;% complete(common_name, historical_site_code, fill = list( `1850-1900` = 0, `1900-1950` = 0, `2021` = 0 ) ) ## site-level relative abundance for 1850-1900 data relSpAbund_1850_1900 &lt;- c() for (i in 1:length(unique(site_level_relAbun$historical_site_code))) { # for every unique historical site a &lt;- site_level_relAbun %&gt;% filter(historical_site_code == unique(site_level_relAbun$historical_site_code)[i]) # subset historical data b &lt;- tibble::deframe(a[, c(1, 3)]) ## choosing 1850-1900 data loc &lt;- unique(site_level_relAbun$historical_site_code)[i] # what&#39;s the site_code? ## historical relative abundance relSpAbund_1850_1900[[i]] &lt;- dirch_stats(b) %&gt;% dplyr::select(species, bayes_mean) old_varname &lt;- c(&quot;species&quot;, &quot;bayes_mean&quot;) new_varname &lt;- c(&quot;common_name&quot;, paste(loc, &quot;_&quot;, &quot;1850&quot;, sep = &quot;&quot;)) relSpAbund_1850_1900[[i]] &lt;- relSpAbund_1850_1900[[i]] %&gt;% data.table::setnames(old = old_varname, new = new_varname) names(relSpAbund_1850_1900)[i] &lt;- loc } # save object but full_join across lists relSpAbund_1850_1900 &lt;- relSpAbund_1850_1900 %&gt;% reduce(.f = full_join) ## site-level relative abundance for 1900-1950 data relSpAbund_1900_1950 &lt;- c() for (i in 1:length(unique(site_level_relAbun$historical_site_code))) { # for every unique historical site a &lt;- site_level_relAbun %&gt;% filter(historical_site_code == unique(site_level_relAbun$historical_site_code)[i]) # subset historical data b &lt;- tibble::deframe(a[, c(1, 4)]) ## choosing 1900-1950 data loc &lt;- unique(site_level_relAbun$historical_site_code)[i] # what&#39;s the site_code? ## historical relative abundance relSpAbund_1900_1950[[i]] &lt;- dirch_stats(b) %&gt;% dplyr::select(species, bayes_mean) old_varname &lt;- c(&quot;species&quot;, &quot;bayes_mean&quot;) new_varname &lt;- c(&quot;common_name&quot;, paste(loc, &quot;_&quot;, &quot;1900&quot;, sep = &quot;&quot;)) relSpAbund_1900_1950[[i]] &lt;- relSpAbund_1900_1950[[i]] %&gt;% data.table::setnames(old = old_varname, new = new_varname) names(relSpAbund_1900_1950)[i] &lt;- loc } # save object but full_join across lists relSpAbund_1900_1950 &lt;- relSpAbund_1900_1950 %&gt;% reduce(.f = full_join) # modern resurvey relative abundance - site level relSpAbund_2021 &lt;- c() for (i in 1:length(unique(site_level_relAbun$historical_site_code))) { a &lt;- site_level_relAbun %&gt;% filter(historical_site_code == unique(site_level_relAbun$historical_site_code)[i]) b &lt;- tibble::deframe(a[, c(1, 5)]) ## choosing modern data loc &lt;- unique(site_level_relAbun$historical_site_code)[i] # what&#39;s the site_code? relSpAbund_2021[[i]] &lt;- dirch_stats(b) %&gt;% dplyr::select(species, bayes_mean) old_varname &lt;- c(&quot;species&quot;, &quot;bayes_mean&quot;) new_varname &lt;- c(&quot;common_name&quot;, paste(loc, &quot;_&quot;, &quot;2021&quot;, sep = &quot;&quot;)) relSpAbund_2021[[i]] &lt;- relSpAbund_2021[[i]] %&gt;% data.table::setnames(old = old_varname, new = new_varname) names(relSpAbund_2021)[i] &lt;- loc } # save object but full_join across lists relSpAbund_2021 &lt;- relSpAbund_2021 %&gt;% reduce(.f = full_join) ## join all the datasets together relSpAbund_by_site &lt;- full_join( relSpAbund_1850_1900, relSpAbund_1900_1950 ) %&gt;% full_join(., relSpAbund_2021) %&gt;% arrange(common_name) 11.9 Visualizing differences in relative abundance over time at the site level ## preparing dataframe for visualization relSpAbund &lt;- relSpAbund_by_site %&gt;% pivot_longer(!common_name, names_to = &quot;site_year&quot;, values_to = &quot;relAbundance&quot;) %&gt;% separate(site_year, into = c(&quot;site&quot;, &quot;year&quot;), sep = &quot;_&quot;) ## Please note: for the sake of downstream analysis, we have renamed 1850-1900 as 1850. In other words, each year - except for 2021 represents a 50 year time period. fig_relAbun_siteLevel &lt;- relSpAbund %&gt;% dplyr::select(-common_name) %&gt;% ggplot(aes( x = year, y = relAbundance, fill = year )) + geom_boxplot() + scale_y_log10() + facet_wrap(~site) + xlab(&quot;Time period&quot;) + ylab(&quot;Relative abundance&quot;) + scale_fill_scico_d(palette = &quot;roma&quot;) + theme_bw() + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text(family = &quot;Century Gothic&quot;, size = 14), legend.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), legend.key.size = unit(1, &quot;cm&quot;), legend.text = element_text(family = &quot;Century Gothic&quot;, size = 14) ) ggsave(fig_relAbun_siteLevel, filename = &quot;figs/fig_relAbun_siteLevel.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Species relative abundances across species, when estimated at the level of the site 11.10 Writing results to file # please be aware that if you are rerunning analysis, the file below is modified and a column is added manually write.csv(relAbun, &quot;results/species-relative-abundance.csv&quot;, row.names = F) write.csv(relSpAbund, &quot;results/species-relative-abundance-siteLevel.csv&quot;, row.names = F) "],["examining-changes-in-relative-abundance-over-time-as-a-function-of-species-habitat-affiliation.html", "Section 12 Examining changes in relative abundance over time as a function of species habitat affiliation 12.1 Load necessary libraries 12.2 Load data on species relative abundances 12.3 Load species trait data 12.4 Analysis to test for significant differences in relative abundances by species across habitat types 12.5 Summary of relative abundance changes by species as a function of habitat affiliation 12.6 Has relative abundance increased or decreased for each species over time? 12.7 Box plots of relative abundance by species trait across time periods 12.8 Are there significant decreases in relative abundance by time periods across habitat affiliations? 12.9 Forest birds 12.10 Grassland birds 12.11 Generalist birds", " Section 12 Examining changes in relative abundance over time as a function of species habitat affiliation In this script, we will examine how relative abundance varies as a function of habitat affiliation across time periods for bird communities. We will plot species rank abundances of relative abundance to estimate how values of relative abundance has shifted for each species. In addition, we will run beta regressions to test for significance in relative abundance changes over time. 12.1 Load necessary libraries library(dplyr) library(stringr) library(tidyverse) library(scico) library(RColorBrewer) library(extrafont) library(sf) library(raster) library(lattice) library(data.table) library(ggrepel) library(report) library(lme4) library(glmmTMB) library(multcomp) library(ggstatsplot) library(paletteer) library(ggpubr) library(goeveg) library(betareg) library(ggeffects) library(patchwork) library(broom) library(ggridges) 12.2 Load data on species relative abundances relAbun &lt;- read.csv(&quot;results/species-relative-abundance-siteLevel.csv&quot;) names(relAbun) &lt;- c(&quot;common_name&quot;, &quot;historical_site_code&quot;, &quot;year&quot;, &quot;relAbundance&quot;) 12.3 Load species trait data ## load in species trait dataset trait_dat &lt;- read.csv(&quot;data/species-trait-dat.csv&quot;) # note: the classification of habitat type was created by comparing habitat affiliation data from the State of India&#39;s Birds report (v2; released in 2023). # this classification was also vetted independently by two reviewers. # We used the following trait classifications: # Forest # Grassland # Generalist # Our criteria for each of these classifications includes the following: # In the 1850s, the land cover change analysis revealed that the majority of the landscape was largely grasslands and forests. However in 2018, the landscape is largely a mosaic of human-modified land cover types - including wooded habitats (mostly comprising timber plantations and degraded forests), tea plantations, followed by forests and grasslands. # While the State of India&#39;s Birds provides a habitat classification/criteria based on contemporary use of habitats by a species, we classified species based on our resurveys and assuming that a species would either be in a forest affiliated bird species, grassland species or a generalist species in the 1850s. # An example in this case is the black and orange flycatcher. While it is commonly found in shola forest habitat, this species is also common in degraded wooded areas, including timber plantations today. However, historically, in the 1850s (due to limited presence of timber plantations compared to 2018), we assume that this is a forest specialist bird as no other wooded habitats apart from forests existed (predominantly) in the 1850s (See 06_land-cover-classification.Rmd) # Other examples include bird species that prefer open habitats, scrubland and dry grassland - such species have been lumped into the Grassland category as this was the closest habitat similar to the above habitat types in 1850s. Eg. Blue-tailed bee-eater, long-tailed shrike, black-winged kite. # If a species is truly a generalist species and is not particularly occupying/specialized on any particular forested/wooded/grassland habitat, it was classified in the generalist category ## join overall relative abundance dataframe and species trait data relAbun &lt;- relAbun %&gt;% left_join(., trait_dat, by = &quot;common_name&quot;) %&gt;% filter(Habitat.type != &quot;Wetland&quot;) %&gt;% # remove wetland birds ungroup() # count distinct number of species affiliated with a particular habitat type spCount &lt;- relAbun[, c(1, 8)] %&gt;% distinct() %&gt;% group_by(Habitat.type) %&gt;% count() # Based on the above criteria, 57 species were classified as forest birds, 9 species were classified as grassland birds, 19 species were classified as generalist species. # visualization by habitat affiliation relAbun$Habitat.type &lt;- factor(relAbun$Habitat.type, levels = c(&quot;Forest&quot;, &quot;Grassland&quot;, &quot;Generalist&quot;)) fig_relAbun_habitat &lt;- grouped_ggbetweenstats( data = relAbun, x = year, y = relAbundance, grouping.var = `Habitat.type`, xlab = &quot;Habitat.type&quot;, ylab = &quot;Relative Abundance&quot;, p.adjust.method = &quot;fdr&quot;, ggplot.component = list(ggplot2::scale_color_discrete(c(&quot;#2c7fb8&quot;, &quot;#025a05&quot;, &quot;#e34a33&quot;))), violin.args = list(width = 0) ) ggsave(fig_relAbun_habitat, filename = &quot;figs/fig_relAbun_habitat_landscapeLevel.png&quot;, width = 17, height = 7, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Relative abundance of grassland bird species was significantly different between 1850-1900 and 2021 and was lower in the modern period compared to the historical period and generalist bird relative abudance was significantly higher in the modern survey period 12.4 Analysis to test for significant differences in relative abundances by species across habitat types ## grassland birds grassland_birds &lt;- relAbun %&gt;% filter(Habitat.type == &quot;Grassland&quot;) plots &lt;- list() for (i in 1:length(unique(grassland_birds$common_name))) { a &lt;- unique(grassland_birds$common_name)[i] # subset data for plotting sp &lt;- grassland_birds[grassland_birds$common_name == a, ] p &lt;- sp %&gt;% ggbetweenstats( x = year, y = relAbundance, xlab = &quot;Time Period&quot;, ylab = &quot;Relative Abundance&quot;, pairwise.display = &quot;significant&quot;, package = &quot;ggsci&quot;, palette = &quot;default_jco&quot;, title = a, violin.args = list(width = 0), plotgrid.args = list(nrow = 3), ggplot.component = list(theme( text = element_text(family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;), plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot; ) )) ) ## save plot object plots[[i]] &lt;- p } # save as a single pdf cairo_pdf( filename = &quot;figs/grassland-bird-relative-abundance-by-TimePeriod.pdf&quot;, width = 13, height = 12, onefile = TRUE ) plots dev.off() ## forest birds forest_birds &lt;- relAbun %&gt;% filter(Habitat.type == &quot;Forest&quot;) plots &lt;- list() for (i in 1:length(unique(forest_birds$common_name))) { a &lt;- unique(forest_birds$common_name)[i] # subset data for plotting sp &lt;- forest_birds[forest_birds$common_name == a, ] p &lt;- sp %&gt;% ggbetweenstats( x = year, y = relAbundance, xlab = &quot;Time Period&quot;, ylab = &quot;Relative Abundance&quot;, pairwise.display = &quot;significant&quot;, package = &quot;ggsci&quot;, palette = &quot;default_jco&quot;, title = a, violin.args = list(width = 0), plotgrid.args = list(nrow = 3), ggplot.component = list(theme( text = element_text(family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;), plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot; ) )) ) ## save plot object plots[[i]] &lt;- p } # save as a single pdf cairo_pdf( filename = &quot;figs/forest-bird-relative-abundance-by-TimePeriod.pdf&quot;, width = 13, height = 12, onefile = TRUE ) plots dev.off() ## generalist birds generalist_birds &lt;- relAbun %&gt;% filter(Habitat.type == &quot;Generalist&quot;) plots &lt;- list() for (i in 1:length(unique(generalist_birds$common_name))) { a &lt;- unique(generalist_birds$common_name)[i] # subset data for plotting sp &lt;- generalist_birds[generalist_birds$common_name == a, ] p &lt;- sp %&gt;% ggbetweenstats( x = year, y = relAbundance, xlab = &quot;Time Period&quot;, ylab = &quot;Relative Abundance&quot;, pairwise.display = &quot;significant&quot;, package = &quot;ggsci&quot;, palette = &quot;default_jco&quot;, title = a, violin.args = list(width = 0), plotgrid.args = list(nrow = 3), ggplot.component = list(theme( text = element_text(family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;), plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot; ) )) ) ## save plot object plots[[i]] &lt;- p } # save as a single pdf cairo_pdf( filename = &quot;figs/generalist-bird-relative-abundance-by-TimePeriod.pdf&quot;, width = 13, height = 12, onefile = TRUE ) plots dev.off() 12.5 Summary of relative abundance changes by species as a function of habitat affiliation Above, we performed an ANOVA to test if there are significant differences in species-specific means of relative abundances. For grassland bird species (n=9) 8/9 species showed a significant difference and a decrease in relative abundance between historical and modern survey periods. No differences were observed across time periods for the Pied Bushchat For Forest birds:(n=57) 27 bird species showed a significant decrease in relative abundance in the modern survey period when compared to either one of the historical time periods. 22 bird species showed no differences in relative abundances across time periods/remained stable. 8 bird species showed a significant increase in relative abundance in the modern survey period when compared to either historical survey periods. ~52.6% of birds have remained stable and/or increase in relative abundance over time. For generalist birds (n=19): 10 birds showed no significant differences in relative abundance across time periods. 4 bird species showed significant increase in the modern survey period compared to either one of the historical time periods. 5 birds showed a significant decrease in relative abundance in the modern survey period compared to either one of the historical survey periods. ~73.6% of birds remained stable or increased in relative abundance over time 12.6 Has relative abundance increased or decreased for each species over time? Based on the above plots and levels of significance for decrease in relative abundance or we create an additional column for each species to denote if a species has increased or remained stable in relative abundance over time. This column is added by manually inspecting the plots for significance and included in the species-relative-abundances.csv file. ## loading the average relative species abundances file ## this file now has a column indicating if a species increased or decreased in relative abundance relAbun_landscape &lt;- read.csv(&quot;results/species-relative-abundance.csv&quot;) names(relAbun_landscape) &lt;- c(&quot;common_name&quot;, &quot;1850-1900&quot;, &quot;1900-1950&quot;, &quot;2021&quot;, &quot;increase_decrease&quot;) relAbun_landscape &lt;- relAbun_landscape %&gt;% left_join(., trait_dat, by = &quot;common_name&quot;) %&gt;% filter(Habitat.type != &quot;Wetland&quot;) %&gt;% # remove wetland birds ungroup() ## merge the above file with species trait data mean_relAbun &lt;- relAbun %&gt;% dplyr::select( common_name, historical_site_code, year, relAbundance, Habitat.type ) %&gt;% group_by(common_name, year) %&gt;% mutate(meanRelAbun = mean(relAbundance)) %&gt;% dplyr::select(common_name, year, meanRelAbun) %&gt;% distinct() %&gt;% left_join(., trait_dat, by = &quot;common_name&quot;) %&gt;% filter(Habitat.type != &quot;Wetland&quot;) %&gt;% # remove wetland birds ungroup() ## summary pie chart fig_relAbun_pieChart &lt;- ggpiestats( # arguments relevant for `ggpiestats()` data = relAbun_landscape, x = increase_decrease, y = Habitat.type, digits.perc = 0, plotgrid.args = list(nrow = 2), ggplot.component = list(theme( text = element_text(family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;), plot.title = element_text( family = &quot;Century Gothic&quot;, size = 18, face = &quot;bold&quot; ), plot.subtitle = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot;, color = &quot;#1b2838&quot; ), axis.title = element_text( family = &quot;Century Gothic&quot;, size = 15, face = &quot;bold&quot; ) )) ) ggsave(fig_relAbun_pieChart, filename = &quot;figs/fig_relativeAbundance_pieChart_increase_decrease.png&quot;, width = 15, height = 6, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() ## Now that we have a summary pie chart showcasing the number of species that increased/remained stable and decreased in relative abundance over time, we can plot the relative abundance for the year 2021 as rank abundance plots ## add increase_decrease column mean_relAbun &lt;- left_join(mean_relAbun, relAbun_landscape[, c(1, 5)]) ## separately for grassland, forest and generalist birds fig_linePlot_grass &lt;- mean_relAbun %&gt;% filter(Habitat.type == &quot;Grassland&quot;) %&gt;% ggplot(., aes( x = year, y = meanRelAbun, group = common_name, color = increase_decrease )) + geom_line(alpha = 0.9) + geom_point(size = 2) + geom_label_repel( data = . %&gt;% filter(year == &quot;1850&quot;), aes(label = common_name), hjust = 1, direction = &quot;y&quot;, nudge_x = -0.1, size = 3, box.padding = 0.5, point.padding = 0.3, segment.color = &quot;lightgrey&quot;, max.overlaps = Inf, force = 10, label.padding = 0.15, label.r = 0.15, fill = &quot;white&quot;, label.size = 0.3, family = &quot;Century Gothic&quot; ) + scale_x_discrete() + scale_y_continuous(limits = c(0, 0.04)) + scale_color_manual(values = c( &quot;decrease&quot; = &quot;#D95F02&quot;, &quot;stable/increase&quot; = &quot;#1B9E77&quot; )) + labs( x = &quot;Year&quot;, y = &quot;Mean Relative Abundance&quot;, title = &quot;Change in Species Relative Abundance (1850-2021)&quot;, color = &quot;Trend&quot; ) + theme_bw() + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_linePlot_grass, filename = &quot;figs/fig_linePlot_grassland.svg&quot;, width = 9, height = 10, device = svg(), units = &quot;in&quot;, dpi = 300) dev.off() ## forest birds fig_linePlot_forest &lt;- mean_relAbun %&gt;% filter(Habitat.type == &quot;Forest&quot;) %&gt;% ggplot(., aes( x = year, y = meanRelAbun, group = common_name, color = increase_decrease )) + geom_line(alpha = 0.9) + geom_point(size = 2) + # Labels for &quot;decrease&quot; (left side) geom_label_repel( data = . %&gt;% filter( year == &quot;1850&quot;, increase_decrease == &quot;decrease&quot; ), aes(label = common_name), hjust = 1, direction = &quot;y&quot;, nudge_x = -1.2, size = 2.5, box.padding = 1.2, point.padding = 0.5, segment.color = &quot;lightgrey&quot;, segment.curvature = 0, force = 50, min.segment.length = 0, max.overlaps = Inf, family = &quot;Century Gothic&quot;, fill = &quot;white&quot;, label.padding = 0.15, label.r = 0.15, label.size = 0.3, ylim = c(0, 0.04) ) + # Labels for &quot;stable/increase&quot; (right side) geom_label_repel( data = . %&gt;% filter( year == &quot;2021&quot;, increase_decrease == &quot;stable/increase&quot; ), aes(label = common_name), hjust = 0, direction = &quot;y&quot;, nudge_x = 1.2, size = 2.5, box.padding = 1.2, point.padding = 0.5, segment.color = &quot;lightgrey&quot;, segment.curvature = 0, force = 50, min.segment.length = 0, max.overlaps = Inf, family = &quot;Century Gothic&quot;, fill = &quot;white&quot;, label.padding = 0.15, label.r = 0.15, label.size = 0.3, ylim = c(0, 0.04) ) + scale_x_discrete(expand = expansion(mult = c(1, 1))) + scale_y_continuous(limits = c(0, 0.04)) + scale_color_manual(values = c( &quot;decrease&quot; = &quot;#D95F02&quot;, &quot;stable/increase&quot; = &quot;#1B9E77&quot; )) + labs( x = &quot;Year&quot;, y = &quot;Mean Relative Abundance&quot;, title = &quot;Change in Species Relative Abundance (1850-2021)&quot;, color = &quot;Trend&quot; ) + theme_bw() + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_linePlot_forest, filename = &quot;figs/fig_linePlot_forest.svg&quot;, width = 15, height = 10, device = svg(), units = &quot;in&quot;, dpi = 300) dev.off() ## generalist birds # please note that the y-lim was modified when compared to grassland and forest birds fig_linePlot_generalist &lt;- mean_relAbun %&gt;% filter(Habitat.type == &quot;Generalist&quot;) %&gt;% ggplot(., aes( x = year, y = meanRelAbun, group = common_name, color = increase_decrease )) + geom_line(alpha = 0.9) + geom_point(size = 2) + # Labels for &quot;decrease&quot; (left side) geom_label_repel( data = . %&gt;% filter( year == &quot;1850&quot;, increase_decrease == &quot;decrease&quot; ), aes(label = common_name), hjust = 1, direction = &quot;y&quot;, nudge_x = -1.2, size = 2.5, box.padding = 1.2, point.padding = 0.5, segment.color = &quot;lightgrey&quot;, segment.curvature = 0, force = 50, min.segment.length = 0, max.overlaps = Inf, family = &quot;Century Gothic&quot;, fill = &quot;white&quot;, label.padding = 0.15, label.r = 0.15, label.size = 0.3, ylim = c(0, 0.04) ) + # Labels for &quot;stable/increase&quot; (right side) geom_label_repel( data = . %&gt;% filter( year == &quot;2021&quot;, increase_decrease == &quot;stable/increase&quot; ), aes(label = common_name), hjust = 0, direction = &quot;y&quot;, nudge_x = 1.2, size = 2.5, box.padding = 1.2, point.padding = 0.5, segment.color = &quot;lightgrey&quot;, segment.curvature = 0, force = 50, min.segment.length = 0, max.overlaps = Inf, family = &quot;Century Gothic&quot;, fill = &quot;white&quot;, label.padding = 0.15, label.r = 0.15, label.size = 0.3, ylim = c(0, 0.04) ) + scale_x_discrete(expand = expansion(mult = c(1, 1))) + scale_y_continuous(limits = c(0, 0.04)) + scale_color_manual(values = c( &quot;decrease&quot; = &quot;#D95F02&quot;, &quot;stable/increase&quot; = &quot;#1B9E77&quot; )) + labs( x = &quot;Year&quot;, y = &quot;Mean Relative Abundance&quot;, title = &quot;Change in Species Relative Abundance (1850-2021)&quot;, color = &quot;Trend&quot; ) + theme_bw() + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_linePlot_generalist, filename = &quot;figs/fig_linePlot_generalist.svg&quot;, width = 12, height = 9, device = svg(), units = &quot;in&quot;, dpi = 300) dev.off() 12.7 Box plots of relative abundance by species trait across time periods # grassland birds fig_boxPlot_grass &lt;- ggplot(grassland_birds, aes(x = common_name, y = relAbundance, fill = factor(year))) + # geom_col()+ geom_boxplot(alpha = 0.7) + scale_fill_manual(values = c(&quot;#2c7fb8&quot;, &quot;#025a05&quot;, &quot;#e34a33&quot;)) + theme_bw() + labs( x = &quot;\\nCommon Name&quot;, y = &quot;Relative Abundance\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_boxPlot_grass, filename = &quot;figs/fig_boxPlot_grassland.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() # forest birds fig_boxPlot_forest &lt;- ggplot(forest_birds, aes(x = common_name, y = relAbundance, fill = factor(year))) + geom_boxplot(alpha = 0.7) + scale_fill_manual(values = c(&quot;#2c7fb8&quot;, &quot;#025a05&quot;, &quot;#e34a33&quot;)) + theme_bw() + labs( x = &quot;\\nCommon Name&quot;, y = &quot;Relative Abundance\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_boxPlot_forest, filename = &quot;figs/fig_boxPlot_forest.png&quot;, width = 22, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() # generalist birds fig_boxPlot_generalist &lt;- ggplot(generalist_birds, aes(x = common_name, y = relAbundance, fill = factor(year))) + geom_boxplot(alpha = 0.7) + scale_fill_manual(values = c(&quot;#2c7fb8&quot;, &quot;#025a05&quot;, &quot;#e34a33&quot;)) + theme_bw() + labs( x = &quot;\\nCommon Name&quot;, y = &quot;Relative Abundance\\n&quot; ) + theme( axis.title = element_text( family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot; ), axis.text = element_text( family = &quot;Century Gothic&quot;, size = 12 ), axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ) ) ggsave(fig_boxPlot_generalist, filename = &quot;figs/fig_boxPlot_generalist.png&quot;, width = 15, height = 10, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() # Grassland birds are the biggest losers; generalist birds are the biggest winners while forest birds show mixed responses depending on the species Grassland bird species suffered the largest decline in relative abundance, while forest and generalist bird species showed increases in relative abundance over time 12.8 Are there significant decreases in relative abundance by time periods across habitat affiliations? We will run beta regressions to answer the above question as the data is bounded between zero and 1. # change the year column to factor relAbun$year &lt;- factor(relAbun$year) beta_overall &lt;- betareg(relAbundance ~ year, data = relAbun) summary(beta_overall) # Call: # betareg(formula = relAbundance ~ factor(year), data = relAbun) # # Standardized weighted residuals 2: # Min 1Q Median 3Q Max # -2.7460 -0.3421 -0.0052 0.1419 4.4420 # # Coefficients (mean model with logit link): # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) -4.42983 0.01317 -336.371 &lt;2e-16 *** # factor(year)1900 0.01608 0.01805 0.891 0.373 # factor(year)2021 -0.22679 0.01899 -11.940 &lt;2e-16 *** # # Phi coefficients (precision model with identity link): # Estimate Std. Error z value Pr(&gt;|z|) # (phi) 261.911 5.357 48.89 &lt;2e-16 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Type of estimator: ML (maximum likelihood) # Log-likelihood: 1.913e+04 on 4 Df # Pseudo R-squared: 0.05352 # Number of iterations: 22 (BFGS) + 3 (Fisher scoring) # plot predicted model estimates fig_beta_overall &lt;- ggpredict(beta_overall) %&gt;% plot() + set_theme( base = theme_bw(), theme.font = &quot;Century Gothic&quot;, axis.title.size = 1.2, axis.textsize = 1, axis.textcolor = &quot;black&quot; ) + ggtitle(&quot;Predicted values of relative abundance for all data&quot;) ggsave(fig_beta_overall, filename = &quot;figs/fig_beta_relAbundance_overall.png&quot;, width = 9, height = 6, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Beta regressions revealed a decline in relative abundance in 2021 when compared to earlier time periods when data was pooled together, irrespective of habitat affiliation. However, the model did not have significant explanatory power (R2 = 0.06) 12.9 Forest birds # change the year column to factor forest_birds$year &lt;- factor(forest_birds$year) beta_forest &lt;- betareg(relAbundance ~ year, data = forest_birds) summary(beta_forest) # Call: # betareg(formula = relAbundance ~ year, data = forest_birds) # # Standardized weighted residuals 2: # Min 1Q Median 3Q Max # -2.8875 -0.3700 -0.0043 0.1296 4.3339 # # Coefficients (mean model with logit link): # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) -4.429361 0.015560 -284.660 &lt;2e-16 *** # year1900 0.008433 0.021403 0.394 0.694 # year2021 -0.239189 0.022568 -10.598 &lt;2e-16 *** # # Phi coefficients (precision model with identity link): # Estimate Std. Error z value Pr(&gt;|z|) # (phi) 281.73 7.02 40.13 &lt;2e-16 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Type of estimator: ML (maximum likelihood) # Log-likelihood: 1.294e+04 on 4 Df # Pseudo R-squared: 0.05652 # Number of iterations: 26 (BFGS) + 2 (Fisher scoring) # plot predicted model estimates fig_beta_forest &lt;- ggpredict(beta_forest) %&gt;% plot() + set_theme( base = theme_bw(), theme.font = &quot;Century Gothic&quot;, axis.title.size = 1.2, axis.textsize = 1, axis.textcolor = &quot;black&quot; ) + ggtitle(&quot;Predicted values of relative abundance for forest bird species&quot;) ggsave(fig_beta_forest, filename = &quot;figs/fig_beta_relAbundance_forestBirds.png&quot;, width = 9, height = 6, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Beta regressions revealed a decline in relative abundance of forest birds in 2021 whe compared to historical time periods. However, the explanatory power of the model is poor (R2 = 0.06) 12.10 Grassland birds grassland_birds$year &lt;- factor(grassland_birds$year) beta_grassland &lt;- betareg(relAbundance ~ year, data = grassland_birds) summary(beta_grassland) # Call: # betareg(formula = relAbundance ~ year, data = grassland_birds) # # Standardized weighted residuals 2: # Min 1Q Median 3Q Max # -4.6046 -0.3444 0.0742 0.1940 5.0030 # # Coefficients (mean model with logit link): # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) -4.512997 0.026442 -170.673 &lt;2e-16 *** # year1900 0.005862 0.036941 0.159 0.874 # year2021 -0.616943 0.043370 -14.225 &lt;2e-16 *** # # Phi coefficients (precision model with identity link): # Estimate Std. Error z value Pr(&gt;|z|) # (phi) 709.31 43.79 16.2 &lt;2e-16 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Type of estimator: ML (maximum likelihood) # Log-likelihood: 2316 on 4 Df # Pseudo R-squared: 0.4275 # Number of iterations: 69 (BFGS) + 2 (Fisher scoring) # plot predicted model estimates fig_beta_grassland &lt;- ggpredict(beta_grassland) %&gt;% plot() + set_theme( base = theme_bw(), theme.font = &quot;Century Gothic&quot;, axis.title.size = 1.2, axis.textsize = 1, axis.textcolor = &quot;black&quot; ) + ggtitle(&quot;Predicted values of relative abundance for grassland bird species&quot;) ggsave(fig_beta_grassland, filename = &quot;figs/fig_beta_relAbundance_grasslandBirds.png&quot;, width = 9, height = 6, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Beta regressions revealed a significant decline in relative abundance in 2021 when compared to historical time periods. The modelâ€™s explanatory power was high (R2 = 0.42) 12.11 Generalist birds generalist_birds$year &lt;- factor(generalist_birds$year) beta_generalist &lt;- betareg(relAbundance ~ year, data = generalist_birds) summary(beta_generalist) # Call: # betareg(formula = relAbundance ~ year, data = generalist_birds) # # Standardized weighted residuals 2: # Min 1Q Median 3Q Max # -2.1571 -0.3896 0.0175 0.1774 3.8070 # # Coefficients (mean model with logit link): # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) -4.40370 0.03241 -135.881 &lt;2e-16 *** # year1900 0.04163 0.04368 0.953 0.341 # year2021 -0.03730 0.04433 -0.841 0.400 # # Phi coefficients (precision model with identity link): # Estimate Std. Error z value Pr(&gt;|z|) # (phi) 180.654 7.907 22.85 &lt;2e-16 *** # --- # Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # # Type of estimator: ML (maximum likelihood) # Log-likelihood: 4059 on 4 Df # Pseudo R-squared: 0.004396 # Number of iterations: 27 (BFGS) + 2 (Fisher scoring) # plot predicted model estimates fig_beta_generalist &lt;- ggpredict(beta_generalist) %&gt;% plot() + set_theme( base = theme_bw(), theme.font = &quot;Century Gothic&quot;, axis.title.size = 1.2, axis.textsize = 1, axis.textcolor = &quot;black&quot; ) + ggtitle(&quot;Predicted values of relative abundance for generalist bird species&quot;) ggsave(fig_beta_generalist, filename = &quot;figs/fig_beta_relAbundance_generalistBirds.png&quot;, width = 9, height = 6, device = png(), units = &quot;in&quot;, dpi = 300) dev.off() Beta regressions revealed no signficant effects of time on generalist bird species relative abundance. The explanatory power of the model was poor (R2=0.004) "],["species-relative-abundance-as-a-function-of-environmental-changes.html", "Section 13 Species relative abundance as a function of environmental changes 13.1 Load necessary libraries 13.2 Load processed land cover rasters 13.3 Load modern resurvey locations 13.4 Create spatial data within a 1000m buffer around each site 13.5 Extract land cover data across locations from the 1848 and the 2018 rasters 13.6 Calculate change in proportions of land cover between time periods 13.7 Calculate change in climate values at sampling sites 13.8 Load species relative abundance 13.9 Load species trait data 13.10 Is there a significant association between change in relative abundance and change in land cover across time periods? 13.11 Test for correlations between covariates 13.12 Running generalized linear mixed effect models for specific habitat affiliations", " Section 13 Species relative abundance as a function of environmental changes In this script, we will model changes in relative abundance as a function of environmental changes across the historical resurvey locations (environmental changes are calculated as differences in values of a predictor between modern vs.Â historical time period) 13.1 Load necessary libraries # load libs library(sf) library(readr) library(dplyr) library(terra) library(tidyr) library(mapview) library(sjPlot) library(glmmTMB) library(ggplot2) library(effects) library(lme4) library(DHARMa) library(ggpubr) library(bbmle) library(betareg) library(extrafont) library(ggeffects) library(sjPlot) library(emmeans) library(scales) # function to z-transform data scale_z &lt;- function(x) { (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) } 13.2 Load processed land cover rasters lc_1848 &lt;- terra::rast(&quot;results/landcover/1848.tif&quot;) lc_2018 &lt;- terra::rast(&quot;results/landcover/2018reclassified.tif&quot;) 13.3 Load modern resurvey locations # load sites sites &lt;- read_csv(&quot;data/list-of-resurvey-locations.csv&quot;) sites &lt;- distinct(sites, modern_site_code, historical_site_code, longitude, latitude) sites &lt;- sites[-c(1:50), ] 13.4 Create spatial data within a 1000m buffer around each site # make spatial data from sites, with a 1000m buffer sites_sf &lt;- st_as_sf( sites, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326 ) |&gt; st_transform(32643) |&gt; st_buffer(1000) 13.5 Extract land cover data across locations from the 1848 and the 2018 rasters # first, we will polygonize the rasters vect1848 &lt;- as.polygons(lc_1848) vect2018 &lt;- as.polygons(lc_2018) # get intersection of the historical resurvey sites with 1848 and 2018 vector data lc_sites &lt;- lapply( list(vect1848, vect2018), function(x) { st_intersection(st_as_sf(x), sites_sf) } ) # calculate total area for each lc type for sites based on historical site code for each time period lc_sites &lt;- lapply(lc_sites, function(df) { df |&gt; mutate( area = as.numeric(st_area(df)) ) |&gt; st_drop_geometry() |&gt; group_by(modern_site_code, name) |&gt; summarise(total_area = sum(area)) }) # add year and merge lc_sites &lt;- Map( lc_sites, c(1848, 2018), f = function(df, y) { df$year &lt;- y df } ) |&gt; bind_rows() # calculate proportion of land cover lc_sites &lt;- lc_sites %&gt;% group_by(modern_site_code, year) %&gt;% mutate(site_total = sum(total_area)) lc_sites &lt;- lc_sites %&gt;% group_by(modern_site_code, name, year) %&gt;% mutate(lcProp = total_area / site_total) 13.6 Calculate change in proportions of land cover between time periods For this calculation, we essentially subtract the proportion of each land cover between time periods to obtain the change # get lc change sites lc_change_dat &lt;- lc_sites |&gt; pivot_wider( id_cols = c(&quot;modern_site_code&quot;, &quot;name&quot;), names_from = c(&quot;year&quot;), values_from = &quot;lcProp&quot;, values_fn = mean ) |&gt; rename( year_1848 = `1848`, year_2018 = `2018` ) %&gt;% left_join(., sites_sf, by = &quot;modern_site_code&quot;) %&gt;% replace(is.na(.), 0) %&gt;% mutate(&quot;lc_prop_change&quot; = (year_2018 - year_1848)) # save as is for further processing write_csv( lc_change_dat, file = &quot;results/lc_change.csv&quot; ) 13.7 Calculate change in climate values at sampling sites # load climate data raster_temp &lt;- list.files(&quot;results/climate/&quot;, pattern = &quot;t_mean&quot;, full.names = T) |&gt; lapply(rast) raster_rain &lt;- list.files(&quot;results/climate/&quot;, pattern = &quot;ppt&quot;, full.names = T) |&gt; lapply(rast) # get difference between first and last files climate_change &lt;- lapply( list(raster_temp, raster_rain), function(le) { lapply(le, function(le2) { le2[[length(names(le2))]] - le2[[1]] }) } ) |&gt; Reduce(f = c) # convert to single list # get raster names climate_change_names &lt;- lapply(climate_change, function(ra) { lapply(ra, function(r) { r |&gt; names() |&gt; stringr::str_extract(&quot;(.*?)(?=_\\\\d+)&quot;) }) }) |&gt; unlist() # get mean change within 1000m buffer of resurvey locs climate_change_sites &lt;- lapply( climate_change, function(ra) { terra::extract( ra, y = terra::vect( sites_sf |&gt; st_transform(4326) ), fun = mean ) } ) # combine all metrics climate_change_sites &lt;- Reduce(f = left_join, x = climate_change_sites) # attach to sampling sites sites &lt;- mutate(sites, ID = seq(nrow(sites))) clim_change_dat &lt;- left_join(sites, climate_change_sites) # save site data write_csv( clim_change_dat, file = &quot;results/climate_change.csv&quot; ) 13.8 Load species relative abundance relAbun &lt;- read.csv(&quot;results/species-relative-abundance-siteLevel.csv&quot;) 13.9 Load species trait data trait_dat &lt;- read.csv(&quot;data/species-trait-dat.csv&quot;) 13.10 Is there a significant association between change in relative abundance and change in land cover across time periods? We will first prepare the dataframes necessary for running linear mixed models. ## preparing the relative abundance dataframe for a mixed effects model names(relAbun) &lt;- c(&quot;common_name&quot;, &quot;historical_site_code&quot;, &quot;year&quot;, &quot;relAbundance&quot;) pivot_1850 &lt;- relAbun %&gt;% filter(year == 1850) %&gt;% pivot_wider(., names_from = &quot;year&quot;, values_from = &quot;relAbundance&quot;) pivot_1900 &lt;- relAbun %&gt;% filter(year == 1900) %&gt;% pivot_wider(., names_from = &quot;year&quot;, values_from = &quot;relAbundance&quot;) pivot_2021 &lt;- relAbun %&gt;% filter(year == 2021) %&gt;% pivot_wider(., names_from = &quot;year&quot;, values_from = &quot;relAbundance&quot;) # calculate difference between modern and historical time periods # positive value implies gain in relative abundance in 2021 compared to 1850, while negative value implies loss in relative abundance in 2021 compared to 1850 relAbun_wide &lt;- full_join(pivot_1850, pivot_2021, by = c(&quot;common_name&quot;, &quot;historical_site_code&quot;)) %&gt;% full_join(., pivot_1900) %&gt;% mutate(&quot;relAbunChange&quot; = (`2021` - `1850`)) ## prepare the land cover data ## calculating mean change at the level of the historical site code lc_meanChange &lt;- lc_change_dat %&gt;% group_by(historical_site_code, name) %&gt;% summarise(lc_prop_change = mean(lc_prop_change)) ## make land cover data wider lc_glmm &lt;- lc_meanChange %&gt;% pivot_wider( id_cols = historical_site_code, names_from = name, values_from = lc_prop_change ) ## join all three dataframes together ## prepare climate change data clim_change_glmm &lt;- clim_change_dat %&gt;% dplyr::select(historical_site_code, t_mean_dry_2010, t_mean_rainy_2010, ppt_dry_2010, ppt_rainy_2010) %&gt;% group_by(historical_site_code) %&gt;% summarise(across(everything(), mean)) ## dataframe for glmm glmm_data &lt;- left_join(relAbun_wide, lc_glmm, by = &quot;historical_site_code&quot; ) %&gt;% as.data.frame() %&gt;% replace(is.na(.), 0) ## scale the climate data glmm_data &lt;- glmm_data %&gt;% mutate(water_bodies_z = scale_z(water_bodies)) %&gt;% mutate(plantations_z = scale_z(plantations)) %&gt;% mutate(agriculture_z = scale_z(agriculture)) %&gt;% mutate(settlements_z = scale_z(settlements)) %&gt;% mutate(shola_forest_z = scale_z(shola_forest)) %&gt;% mutate(shola_grassland_z = scale_z(shola_grassland)) 13.11 Test for correlations between covariates library(psych) for_corr &lt;- glmm_data[, c(12:17)] %&gt;% distinct() pairs.panels(for_corr) 13.12 Running generalized linear mixed effect models for specific habitat affiliations glmm_habitat &lt;- left_join(glmm_data, trait_dat, by = &quot;common_name&quot;) ## all birds model m1 &lt;- glmmTMB( relAbunChange ~ shola_grassland_z + shola_forest_z + agriculture_z + plantations_z + settlements_z + (1 | common_name) + (1 | historical_site_code), family = gaussian(), data = glmm_habitat ) summary(m1) plot_model(m1, type = &quot;std&quot;) plot(ggpredict(m1)) # Family: gaussian ( identity ) # Formula: # relAbunChange ~ shola_grassland_z + shola_forest_z + agriculture_z + # plantations_z + settlements_z + (1 | common_name) + (1 | # historical_site_code) # Data: glmm_habitat # # AIC BIC logLik deviance df.resid # -11053.6 -11003.9 5535.8 -11071.6 1831 # # Random effects: # # Conditional model: # Groups Name Variance Std.Dev. # common_name (Intercept) 9.793e-05 9.896e-03 # historical_site_code (Intercept) 6.316e-14 2.513e-07 # Residual 1.239e-04 1.113e-02 # Number of obs: 1840, groups: common_name, 92; historical_site_code, 20 # # Dispersion estimate for gaussian family (sigma^2): 0.000124 # # Conditional model: # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) 4.061e-11 1.064e-03 0 1 # shola_grassland_z 1.619e-10 1.587e-03 0 1 # shola_forest_z 1.346e-10 2.148e-03 0 1 # agriculture_z 1.054e-10 1.756e-03 0 1 # plantations_z 1.634e-10 2.278e-03 0 1 # settlements_z 4.717e-11 1.132e-03 0 1 ## grassland birds glmm_grassland &lt;- glmm_habitat %&gt;% filter(Habitat.type == &quot;Grassland&quot;) # linear mixed model m2 &lt;- glmmTMB( relAbunChange ~ shola_grassland_z + (1 | common_name) + (1 | historical_site_code), family = gaussian(), data = glmm_grassland ) summary(m2) plot_model(m2, type = &quot;std&quot;) plot(ggpredict(m2)) # Family: gaussian ( identity ) # Formula: # relAbunChange ~ shola_grassland_z + (1 | common_name) + (1 | # historical_site_code) # Data: glmm_grassland # # AIC BIC logLik deviance df.resid # -1352.7 -1336.8 681.4 -1362.7 175 # # Random effects: # # Conditional model: # Groups Name Variance Std.Dev. # common_name (Intercept) 2.034e-06 0.001426 # historical_site_code (Intercept) 3.103e-06 0.001761 # Residual 2.665e-05 0.005163 # Number of obs: 180, groups: common_name, 9; historical_site_code, 20 # # Dispersion estimate for gaussian family (sigma^2): 2.67e-05 # # Conditional model: # Estimate Std. Error z value Pr(&gt;|z|) # (Intercept) -0.0052244 0.0007275 -7.182 6.89e-13 *** # shola_grassland_z 0.0002718 0.0005508 0.493 0.622 # --- # Signif. codes: 0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 # Above, we asked if grassland species are declining relative to other species, and we found that there was no association between changes in land cover and climate on grassland bird species abundance, indicating that both grassland habitat loss and has been uniform across locations suggesting a regional-scale process and not local-scale. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
